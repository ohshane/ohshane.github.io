[
  {
    "objectID": "posts/VibrationAnalysis.html",
    "href": "posts/VibrationAnalysis.html",
    "title": "Vibration Analysis",
    "section": "",
    "text": "Vibration analysis is a critical aspect of mechanical engineering, allowing us to understand and optimize the dynamic behavior of machinery and structures. From diagnosing faults to designing stable systems, vibration analysis plays a pivotal role in ensuring reliability and safety."
  },
  {
    "objectID": "posts/VibrationAnalysis.html#introduction",
    "href": "posts/VibrationAnalysis.html#introduction",
    "title": "Vibration Analysis",
    "section": "",
    "text": "Vibration analysis is a critical aspect of mechanical engineering, allowing us to understand and optimize the dynamic behavior of machinery and structures. From diagnosing faults to designing stable systems, vibration analysis plays a pivotal role in ensuring reliability and safety."
  },
  {
    "objectID": "posts/VibrationAnalysis.html#objectives-of-vibration-analysis",
    "href": "posts/VibrationAnalysis.html#objectives-of-vibration-analysis",
    "title": "Vibration Analysis",
    "section": "Objectives of Vibration Analysis",
    "text": "Objectives of Vibration Analysis\n\nDesign Optimization\n\nPrevent resonance, which can cause excessive amplitude and potential failure.\nExample: Turbine blades, aircraft wings, building structures.\n\nCondition Monitoring and Fault Diagnosis\n\nEarly detection of faults in components like bearings, gears, and shafts.\nSupports predictive maintenance (PM) by identifying anomalies in frequency data.\nStrategies of PM.\n\nTBM: Time-based maintenance\nCBM: Condition-based maintenance"
  },
  {
    "objectID": "posts/VibrationAnalysis.html#key-techniques",
    "href": "posts/VibrationAnalysis.html#key-techniques",
    "title": "Vibration Analysis",
    "section": "Key Techniques",
    "text": "Key Techniques\n\nTime Domain Analysis\nExamines signal variations over time to compute values like:\n\nRMS (Root Mean Square)\nPeak-to-peak amplitude\nMaximum amplitude\n\n\n\nFrequency Domain Analysis\nTransforms signals to the frequency domain to analyze components like:\n\nDominant frequencies\nAmplitude and phase relationships\nFast Fourier Transform (FFT)"
  },
  {
    "objectID": "posts/VibrationAnalysis.html#applications-in-real-world-scenarios",
    "href": "posts/VibrationAnalysis.html#applications-in-real-world-scenarios",
    "title": "Vibration Analysis",
    "section": "Applications in Real-World Scenarios",
    "text": "Applications in Real-World Scenarios\n\nRotating Machinery\n\nDiagnose bearing faults by detecting anomalies at specific frequencies.\nIdentify imbalances based on amplitude in rotational frequencies."
  },
  {
    "objectID": "posts/Tmux.html",
    "href": "posts/Tmux.html",
    "title": "Tmux",
    "section": "",
    "text": "Start off with installing tmux with homebrew on Mac."
  },
  {
    "objectID": "posts/Tmux.html#intro",
    "href": "posts/Tmux.html#intro",
    "title": "Tmux",
    "section": "Intro",
    "text": "Intro\nThere are three main concepts in tmux: session, window, and pane. Start by entering tmux in the terminal.\nThe screen you see right after entering the command is a pane in a window."
  },
  {
    "objectID": "posts/Tmux.html#pane",
    "href": "posts/Tmux.html#pane",
    "title": "Tmux",
    "section": "Pane",
    "text": "Pane\nSplit the pane using Ctrl-bCtrl-b %% and Ctrl-bCtrl-b \"\".\nThe Ctrl-bCtrl-b works as a prefix to send a command — later below.\nNavigate through the panes using Ctrl-bCtrl-b ↑↑, Ctrl-bCtrl-b →→, Ctrl-bCtrl-b ↓↓, Ctrl-bCtrl-b ←←."
  },
  {
    "objectID": "posts/Tmux.html#window",
    "href": "posts/Tmux.html#window",
    "title": "Tmux",
    "section": "Window",
    "text": "Window\nOpen a new window with Ctrl-bCtrl-b cc.\nSee the windows you opened on the bottom green bar? This gives us some information about the windows in the session. The current window you are seeing is marked with an *.\nNavigate through the windows using Ctrl-bCtrl-b nn — n is for next. This will cycle through all the windows in the current session. Reverse navigate with Ctrl-bCtrl-b pp — p is for previous. You can also navigate directly to a window using the index. The bindings will be like Ctrl-bCtrl-b 11."
  },
  {
    "objectID": "posts/Tmux.html#session",
    "href": "posts/Tmux.html#session",
    "title": "Tmux",
    "section": "Session",
    "text": "Session\nFrom the very first, right after the tmux command, you are attached to a session with an auto generated index. Detach the session with the Ctrl-bCtrl-b dd command — and d is for detach. It’s almost the same as starting the bash session and detaching with the exit command. Tmux can also be detached using the exit command, but this can be tedious because each split pane needs to be closed individually with the exit command."
  },
  {
    "objectID": "posts/Tmux.html#configurations",
    "href": "posts/Tmux.html#configurations",
    "title": "Tmux",
    "section": "Configurations",
    "text": "Configurations\nFeeling comfortable with the keybindings? I hope not. The default keybindings can put significant stress on your left pinky. This brings us to the .tmux.conf file for some configuration.\n\n\n~/.tmux.conf\n\nunbind-key C-b\nset -g prefix C-a\n1bind-key C-a send-prefix\n\n2set -g mouse on\n3set -g base-index 1\nset -g renumber-windows on\nset -g default-terminal \"tmux-256color\"\n\n4bind r source-file ~/.tmux.conf \\; display-message \".tmux.conf reloaded!\"\n\n5bind '\\' split-window -h -c \"#{pane_current_path}\"\n6bind - split-window -v -c \"#{pane_current_path}\"\n\n7bind h select-pane -L\nbind j select-pane -D\nbind k select-pane -U\nbind l select-pane -R\n\n8bind x kill-pane\n9bind X kill-window\n\n\n1\n\nReplace the prefix key from Ctrl-bCtrl-b to Ctrl-aCtrl-a. When you are using a keyboard like HHKB, this will come in pretty handy. Let’s talk more about HHKB in some other posts.\n\n2\n\nPretty straight forward. Helps you navigate split panes with a mouse.\n\n3\n\nThe default is 0. For me, 0 key is a bit far for everyday use.\n\n4\n\nReload the .tmux.conf file and display a message when done — similar to something like source .bashrc.\n\n5\n\nSplit the window horizontally using the current pane’s path.\n\n6\n\nSplit the window vertically using the current pane’s path.\n\n7\n\nMove between panes using Vim-style keybindings.\n\n8\n\nKill the current pane.\n\n9\n\nKill the current window.\n\n\nPersonal preference on the following one.\n\n\n.zshrc\n\ntmux() {\n    if [ \"$#\" -eq 0 ]; then\n1        command tmux new-session -A -s default\n    else\n        command tmux \"$@\"\n    fi\n}\n\n\n1\n\nAttach a session named default when tmux is typed."
  },
  {
    "objectID": "posts/NginxIngress.html",
    "href": "posts/NginxIngress.html",
    "title": "Ingress",
    "section": "",
    "text": "This document is based on a bare-metal Raspberry Pi Kubernetes (K8s) cluster, as discussed in the previous post. To facilitate external access, a load balancer like MetalLB is required. The setup of MetalLB was covered in the previous post.\nFor this guide, we will use the Ingress-Nginx Controller."
  },
  {
    "objectID": "posts/NginxIngress.html#introduction",
    "href": "posts/NginxIngress.html#introduction",
    "title": "Ingress",
    "section": "Introduction",
    "text": "Introduction\nSo, what is an ingress? There are two kinds of network communication: Ingress and Egress.\n\nIngress — Controls external access to services within the cluster, typically via HTTP/HTTPS. It acts as a gateway for handling incoming traffic and routing it to the appropriate backend services.\nEgress — Manages outbound traffic from the cluster to external services. It defines policies to regulate how pods can communicate with external networks.\n\nIngress is particularly useful for exposing services via a single endpoint while managing SSL termination, path-based routing, and load balancing. In contrast, egress rules help enforce security by restricting outbound connections. Manipulating ingress resource is similar to manipulating Nginx server with nginx.conf.\nThe basic architecture is as follows.\n\n\n\n\n\n\nFigure 1: Nginx ingress architecture\n\n\n\nThere is a detailed post about the Ingress-Nginx Controller from the AWS blog. Simply replace the load balancer in the Figure 1 with MetalLB service which is already exposed using the Ingress-Nginx Controller Service. This comes right out of the box."
  },
  {
    "objectID": "posts/NginxIngress.html#installation",
    "href": "posts/NginxIngress.html#installation",
    "title": "Ingress",
    "section": "Installation",
    "text": "Installation\nInstalling the NGINX Ingress Controller is straightforward. Refer to the official guide and apply the following configuration.\nThis setup includes two primary components:\n\nDeployment — responsible for running the ingress controller pods\nService — exposing the ingress controller to the network\n\napiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    app.kubernetes.io/component: controller\n    app.kubernetes.io/instance: ingress-nginx\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\n    app.kubernetes.io/version: 1.12.0\n  name: ingress-nginx-controller\n  namespace: ingress-nginx\nspec:\n  ipFamilies:\n  - IPv4\n  ipFamilyPolicy: SingleStack\n  ports:\n  - appProtocol: http\n    name: http\n    port: 80\n    protocol: TCP\n    targetPort: http\n  - appProtocol: https\n    name: https\n    port: 443\n    protocol: TCP\n    targetPort: https\n  selector:\n    app.kubernetes.io/component: controller\n    app.kubernetes.io/instance: ingress-nginx\n    app.kubernetes.io/name: ingress-nginx\n1  type: NodePort\n\n1\n\nThe default network type is NodePort. Change this to LoadBalancer when using MetalLB."
  },
  {
    "objectID": "posts/NginxIngress.html#exposing-the-ingress-controller",
    "href": "posts/NginxIngress.html#exposing-the-ingress-controller",
    "title": "Ingress",
    "section": "Exposing the Ingress Controller",
    "text": "Exposing the Ingress Controller\nTo expose the ingress controller, define a service of type NodePort or LoadBalancer.\n$ kubectl edit svc ingress-nginx-controller -n ingress-nginx\nTo route traffic to services inside your cluster, create an Ingress resource. This routes https://shaneoh.org traffic to the https://www.shaneoh.org Kubernetes service on port 80.\n\n\nredirect-root-to-www.yaml\n\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: redirect-root-to-www\n  namespace: default\n  annotations:\n1    nginx.ingress.kubernetes.io/rewrite-target: /\n    nginx.ingress.kubernetes.io/permanent-redirect: \"http://www.shaneoh.org\"\nspec:\n  ingressClassName: nginx\n  rules:\n  - host: \"shaneoh.org\"\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: placeholder-service\n            port:\n              number: 80\n\n\n1\n\nThe routing path handled by the ingress service is omitted and then passed to the services.\n\n\nAfter creating the resource, check if it is running correctly by:\n$ kubectl get ingress\n\nNAME                   CLASS   HOSTS         ADDRESS        PORTS   AGE\nredirect-root-to-www   nginx   shaneoh.org   192.168.0.11   80      5d9h\nStay tuned for future posts covering advanced ingress configurations, including Let’s Encrypt TLS using cert-manager."
  },
  {
    "objectID": "posts/Kubeconfig.html",
    "href": "posts/Kubeconfig.html",
    "title": ".kube/config",
    "section": "",
    "text": "I have set up Minikube on my MacBook for an easy development environment, and at home, I have a Raspberry Pi cluster set up for my homelab. These configurations allow me to access and manage my clusters from anywhere. Specifically, I have properly configured the .kube/config file to enable remote access to the cluster at home.\nBelow is an example of the configured .kube/config file:\n\n\n.kube/config\n\n\napiVersion: v1\nclusters:\n- cluster:\n    certificate-authority-data: LS0...LS0tCg==\n    server: https://kubernetes.docker.internal:6443\n  name: docker-desktop\n- cluster:\n    insecure-skip-tls-verify: true\n    server: https://121.135.111.111:6443\n  name: raspberrypi\n- cluster:\n    certificate-authority: /Users/shane/.minikube/ca.crt\n    extensions:\n    - extension:\n        last-update: Sun, 20 Aug 2023 17:04:00 KST\n        version: v1.30.1\n        provider: minikube.sigs.k8s.io\n      name: cluster_info\n    server: https://127.0.0.1:60544\n  name: minikube\n\nThe above configuration file defines three clusters:\n\ndocker-desktop\nraspberrypi (the Raspberry Pi cluster at home, with the server address https://121.135.111.111:6443)\nminikube\n\nWith this configuration file, you can easily access various clusters using the kubectl command. For example, to access the Raspberry Pi cluster, you can use the following command:\nkubectl config use-context raspberrypi\nTo bypass the process of verifying the SSL certificate as a public certificate, use the following command:\n- cluster:\n    insecure-skip-tls-verify: true"
  },
  {
    "objectID": "posts/InternallyDividingPoint.html",
    "href": "posts/InternallyDividingPoint.html",
    "title": "Internally Dividing Point",
    "section": "",
    "text": "Figure 1: Internally dividing point\n\n\n\nInternally dividing point is defined as follows:\n\\[\n\\begin{align*}\nz &= (y-x) \\cdot \\dfrac{a}{a+b} + x \\\\[10pt]\n&= \\dfrac{ay - ax + ax + bx}{a+b} \\\\[10pt]\n&= \\dfrac{bx + ay}{a+b}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "posts/GoConcurrency.html",
    "href": "posts/GoConcurrency.html",
    "title": "Go Concurrency",
    "section": "",
    "text": "Checkout the video by Ben Davis. Great explanation!\nI recently started learning Go (Golang) and I find it easy to pick up. There isn’t much magic involved, which gives me a solid, reliable feeling when working with it.\nLet’s get right into the concurrency world of Go."
  },
  {
    "objectID": "posts/GoConcurrency.html#wait-group",
    "href": "posts/GoConcurrency.html#wait-group",
    "title": "Go Concurrency",
    "section": "Wait Group",
    "text": "Wait Group\nSo, what is a WaitGroup?\nA WaitGroup waits for a collection of goroutines to finish. The main goroutine calls Add to set the number of goroutines to wait for. Each of the goroutines runs and calls Done when finished. We make sure to call Done with a defer keyword. At the same time, you can use Wait to block until all goroutines have finished.\npackage main\n\nimport (\n    \"fmt\"\n    \"sync\"\n)\n\nfunc main() {\n    names := []string{\n        \"Alice\",\n        \"Bob\",\n        \"Chuck\",\n        \"Dan\",\n        \"Ed\",\n        \"Fred\",\n        \"Greg\",\n    }\n\n    var wg sync.WaitGroup\n\n    for _, name := range names {\n        wg.Add(1)\n        go func(name string) {\n            defer wg.Done()\n            sayHello(name)\n        }(name)\n    }\n    wg.Wait()\n}\n\nfunc sayHello(name string) {\n    fmt.Printf(\"Hello %v\\n\", name)\n}\nHello Greg\nHello Ed\nHello Fred\nHello Alice\nHello Chuck\nHello Dan\nHello Bob\n\n\n\n\n\n\nNote\n\n\n\nThink of wg as a counter. The counter increments with the values passed into Add and decreases by one with the Done method."
  },
  {
    "objectID": "posts/GoConcurrency.html#channels",
    "href": "posts/GoConcurrency.html#channels",
    "title": "Go Concurrency",
    "section": "Channels",
    "text": "Channels\npackage main\n\nimport \"fmt\"\n\nfunc main() {\n1    ch := make(chan int)\n\n    go func() {\n        ch &lt;- 1\n        ch &lt;- 2\n        ch &lt;- 3\n2        close(ch)\n    }()\n\n    fmt.Println(&lt;-ch)\n    fmt.Println(&lt;-ch)\n    fmt.Println(&lt;-ch)\n3    fmt.Println(&lt;-ch)\n}\n\n1\n\nA new channel is spawned with a make function.\n\n2\n\nWe need to close the channel with close function, otherwise the fourth &lt;-ch will cause a dead lock since all goroutines are asleep.\n\n3\n\nReceiving from a closed channel does not cause a panic or runtime error. In this case, 0 is printed.\n\n\n1\n2\n3\n0\npackage main\n\nimport \"fmt\"\n\nfunc main() {\n    ch := make(chan int)\n    value := make(chan int)\n\n    go func() {\n        for i := 1; i &lt; 4; i++ {\n            ch &lt;- i\n        }\n        close(ch)\n    }()\n\n    go sum(ch, value)\n\n1    fmt.Println(&lt;-value)\n}\n\nfunc sum(ch, value chan int) {\n    total := 0\n\n2    for {\n        select {\n3        case num, ok := &lt;-ch:\n            fmt.Println(num, ok)\n            if !ok {\n                value &lt;- total\n                return\n            }\n            total += num\n        }\n    }\n}\n\n1\n\nThis line waits for all the goroutines to be finished.\n\n2\n\nSyntactic sugar with for and select. You can select from multiple channels like this.\n\n3\n\nThe second return value is a boolean which indicates the channel is open or not.\n\n\n1 true\n2 true\n3 true\n0 false\n6"
  },
  {
    "objectID": "posts/Git.html",
    "href": "posts/Git.html",
    "title": "Local Git Commands",
    "section": "",
    "text": "Thanks Cottle for creating this educational tool. Ever thought of Git graphs as linked lists? Here is a great explanation.\nFirst things first,"
  },
  {
    "objectID": "posts/Git.html#git-commit",
    "href": "posts/Git.html#git-commit",
    "title": "Local Git Commands",
    "section": "git commit",
    "text": "git commit\nThis creates a new commit C1, which references where it was based off of — in this case, a C0 which is a initial commit becomes the parent.\ngit commit\n\n\n\n\n\n\n\n\n\n\nflowchart TB\n  main:::pointer -.-&gt; C0:::commit\n  HEAD:::pointer -.-&gt; main\n  classDef commit fill: #abc, color: #000\n  classDef pointer fill: #fff, color #000, font: #000\n\n\n\n\n\n\n\n\n\n\n\nflowchart TB\n  C1:::commit --&gt; C0:::commit\n  main:::pointer -.-&gt; C1\n  HEAD:::pointer -.-&gt; main\n  classDef commit fill: #abc, color: #000\n  classDef pointer fill: #fff, color #000, font: #000"
  },
  {
    "objectID": "posts/Git.html#git-branch",
    "href": "posts/Git.html#git-branch",
    "title": "Local Git Commands",
    "section": "git branch",
    "text": "git branch\nBranches is Git are simply pointers to a specific commit – nothing more. This is why many Git enthusiasts chant the mantra\n\nbranch early, and branch often.\n\nWhen we start mixing branches (pointers) and commits, we will see how these two features combine. For now, just remember that a branch essentially says\n\nI want to include the work of this commit and all parent commits.\n\ngit checkout main\ngit branch dev\n\n\n\n\n\n\n\n\n\n\nflowchart TB\n  C1:::commit --&gt; C0:::commit\n  main:::pointer -.-&gt; C1\n  HEAD:::pointer -.-&gt; main\n  classDef commit fill: #abc, color: #000\n  classDef pointer fill: #fff, color #000, font: #000\n\n\n\n\n\n\n\n\n\n\n\nflowchart TB\n  C1:::commit --&gt; C0:::commit\n  main:::pointer -.-&gt; C1\n  dev:::pointer -.-&gt; C1\n  HEAD:::pointer -.-&gt; main\n  classDef commit fill: #abc, color: #000\n  classDef pointer fill: #fff, color #000, font: #000\n\n\n\n\n\n\n\n\ngit checkout main\ngit checkout -b dev\ngit checkout main\ngit switch -c dev\n\n\n\n\n\n\n\n\n\n\nflowchart TB\n  C1:::commit --&gt; C0:::commit\n  main:::pointer -.-&gt; C1\n  HEAD:::pointer -.-&gt; main\n  classDef commit fill: #abc, color: #000\n  classDef pointer fill: #fff, color #000, font: #000\n\n\n\n\n\n\n\n\n\n\n\nflowchart TB\n  C1:::commit --&gt; C0:::commit\n  main:::pointer -.-&gt; C1\n  dev:::pointer -.-&gt; C1\n  HEAD:::pointer -.-&gt; dev\n  classDef commit fill: #abc, color: #000\n  classDef pointer fill: #fff, color #000, font: #000"
  },
  {
    "objectID": "posts/Git.html#git-merge",
    "href": "posts/Git.html#git-merge",
    "title": "Local Git Commands",
    "section": "git merge",
    "text": "git merge\nmerge command eventually creates a special commit which has two unique parents. A commit with two parents essentially means\n\nI want to include all the work from both parents, and the set of all their parents.\n\ngit checkout main\n1git merge dev\ngit checkout dev\n2git merge main\n\n1\n\nThe command merges dev branch into the current main branch. This leaves the dev branch (pointer) behind.\n\n2\n\nWe don’t need to derive the work from both the main and dev parents again because the dev graph is a subgraph of the main graph. Instead, we can simply move the dev pointer to match the position of the main pointer. This is also called fast forward.\n\n\n\n\n\n\n\n\n\n\n\n\nflowchart TB\n  C1:::commit --&gt; C0:::commit\n  C2:::commit --&gt; C1:::commit\n  C3:::commit --&gt; C1:::commit\n  main:::pointer -.-&gt; C2\n  dev:::pointer -.-&gt; C3\n  HEAD:::pointer -.-&gt; main\n  classDef commit fill: #abc, color: #000\n  classDef pointer fill: #fff, color #000, font: #000\n\n\n\n\n\n\n\n\n\n\n\nflowchart TB\n  C1:::commit --&gt; C0:::commit\n  C2:::commit --&gt; C1:::commit\n  C3:::commit --&gt; C1:::commit\n  C4:::commit --&gt; C2:::commit\n  C4:::commit --&gt; C3:::commit\n\n  main:::pointer -.-&gt; C4\n  dev:::pointer -.-&gt; C3\n  HEAD:::pointer -.-&gt; main\n  classDef commit fill: #abc, color: #000\n  classDef pointer fill: #fff, color #000, font: #000\n\n\n\n\n\n\n\n\n\n\n\nflowchart TB\n  C1:::commit --&gt; C0:::commit\n  C2:::commit --&gt; C1:::commit\n  C3:::commit --&gt; C1:::commit\n  C4:::commit --&gt; C2:::commit\n  C4:::commit --&gt; C3:::commit\n\n  main:::pointer -.-&gt; C4\n  dev:::pointer -.-&gt; C3\n  HEAD:::pointer -.-&gt; dev\n  classDef commit fill: #abc, color: #000\n  classDef pointer fill: #fff, color #000, font: #000\n\n\n\n\n\n\n\n\n\n\n\nflowchart TB\n  C1:::commit --&gt; C0:::commit\n  C2:::commit --&gt; C1:::commit\n  C3:::commit --&gt; C1:::commit\n  C4:::commit --&gt; C2:::commit\n  C4:::commit --&gt; C3:::commit\n\n  main:::pointer -.-&gt; C4\n  dev:::pointer -.-&gt; C4\n  HEAD:::pointer -.-&gt; dev\n  classDef commit fill: #abc, color: #000\n  classDef pointer fill: #fff, color #000, font: #000"
  },
  {
    "objectID": "posts/Git.html#git-rebase",
    "href": "posts/Git.html#git-rebase",
    "title": "Local Git Commands",
    "section": "git rebase",
    "text": "git rebase\nrebase copies the commits and stack them on somewhere else.\n\n\n\n\n\n\nNote\n\n\n\nThe position of the HEAD pointer is different when merging and rebasing.\ngit checkout main # &lt;- HEAD\ngit merge dev\ngit checkout dev # &lt;- HEAD\ngit rebase main\nWhen rebasing, we are willing to rebase with copied commits onto main.\n\n\ngit checkout dev\ngit rebase main\ngit checkout main\ngit merge dev\n\n\n\n\n\n\n\n\n\n\nflowchart TB\n  C1:::commit --&gt; C0:::commit\n  C2:::commit --&gt; C1:::commit\n  C3:::commit --&gt; C1:::commit\n  C4:::commit --&gt; C3:::commit\n  main:::pointer -.-&gt; C2\n  dev:::pointer -.-&gt; C4\n  HEAD:::pointer -.-&gt; dev\n  classDef commit fill: #abc, color: #000\n  classDef pointer fill: #fff, color #000, font: #000\n\n\n\n\n\n\n\n\n\n\n\nflowchart TB\n  C1:::commit --&gt; C0:::commit\n  C2:::commit --&gt; C1:::commit\n  C3':::commit --&gt; C2:::commit\n  C4':::commit --&gt; C3':::commit\n  main:::pointer -.-&gt; C2\n  dev:::pointer -.-&gt; C4'\n  HEAD:::pointer -.-&gt; dev\n  classDef commit fill: #abc, color: #000\n  classDef pointer fill: #fff, color #000, font: #000\n\n\n\n\n\n\n\n\n\n\n\nflowchart TB\n  C1:::commit --&gt; C0:::commit\n  C2:::commit --&gt; C1:::commit\n  C3':::commit --&gt; C2:::commit\n  C4':::commit --&gt; C3':::commit\n  main:::pointer -.-&gt; C2\n  dev:::pointer -.-&gt; C4'\n  HEAD:::pointer -.-&gt; main\n  classDef commit fill: #abc, color: #000\n  classDef pointer fill: #fff, color #000, font: #000\n\n\n\n\n\n\n\n\n\n\n\nflowchart TB\n  C1:::commit --&gt; C0:::commit\n  C2:::commit --&gt; C1:::commit\n  C3':::commit --&gt; C2:::commit\n  C4':::commit --&gt; C3':::commit\n  main:::pointer -.-&gt; C4'\n  dev:::pointer -.-&gt; C4'\n  HEAD:::pointer -.-&gt; main\n  classDef commit fill: #abc, color: #000\n  classDef pointer fill: #fff, color #000, font: #000"
  },
  {
    "objectID": "posts/Git.html#git-checkout",
    "href": "posts/Git.html#git-checkout",
    "title": "Local Git Commands",
    "section": "git checkout",
    "text": "git checkout\nDidn’t we use the git checkout command without any discomfort so far? What checkout does is point HEAD to the desired object such as a branch or a commit.\ngit checkout 1b7979e16daafabf7c052411b083ea9e2e8a13d5\n\nRelative reference (^ and ~)\ngit checkout C1\ngit checkout C2^\ngit checkout main^^\ngit checkout main~2\ngit checkout HEAD^; git checkout HEAD^\n\n\n\n\n\n\n\n\n\n\nflowchart TB\n  C1:::commit --&gt; C0:::commit\n  C2:::commit --&gt; C1:::commit\n  C3:::commit --&gt; C2:::commit\n  main:::pointer -.-&gt; C3\n  HEAD:::pointer -.-&gt; main\n  classDef commit fill: #abc, color: #000\n  classDef pointer fill: #fff, color #000, font: #000\n\n\n\n\n\n\n\n\n\n\n\nflowchart TB\n  C1:::commit --&gt; C0:::commit\n  C2:::commit --&gt; C1:::commit\n  C3:::commit --&gt; C2:::commit\n  main:::pointer -.-&gt; C3\n  HEAD:::pointer -.-&gt; C1\n  classDef commit fill: #abc, color: #000\n  classDef pointer fill: #fff, color #000, font: #000\n\n\n\n\n\n\n\n\n\n\nBranch forcing (git branch -f)\nThis is called branch forcing.\ngit branch -f feature dev^\n\n\n\n\n\n\n\n\n\n\nflowchart TB\n  C1:::commit --&gt; C0:::commit\n  C2:::commit --&gt; C1:::commit\n  C3:::commit --&gt; C1:::commit\n  C4:::commit --&gt; C3:::commit\n  C5:::commit --&gt; C4:::commit\n  C6:::commit --&gt; C5:::commit\n  C7:::commit --&gt; C4:::commit\n  main:::pointer -.-&gt; C2\n  dev:::pointer -.-&gt; C6\n  feature:::pointer -.-&gt; C7\n  HEAD:::pointer -.-&gt; main\n  classDef commit fill: #abc, color: #000\n  classDef pointer fill: #fff, color #000, font: #000\n\n\n\n\n\n\n\n\n\n\n\nflowchart TB\n  C1:::commit --&gt; C0:::commit\n  C2:::commit --&gt; C1:::commit\n  C3:::commit --&gt; C1:::commit\n  C4:::commit --&gt; C3:::commit\n  C5:::commit --&gt; C4:::commit\n  C6:::commit --&gt; C5:::commit\n  main:::pointer -.-&gt; C2\n  dev:::pointer -.-&gt; C6\n  feature:::pointer -.-&gt; C5\n  HEAD:::pointer -.-&gt; main\n  classDef commit fill: #abc, color: #000\n  classDef pointer fill: #fff, color #000, font: #000"
  },
  {
    "objectID": "posts/Git.html#git-reset",
    "href": "posts/Git.html#git-reset",
    "title": "Local Git Commands",
    "section": "git reset",
    "text": "git reset\nThe reset command is often used to undo changes that have been staged or committed. This sets the HEAD to the desired commit object. The most common command will be as follows.\nUndoing the add command.\ngit reset\ngit reset HEAD\nThis command moves HEAD to the parent of the current commit (HEAD^), effectively undoing the most recent commit.\ngit reset HEAD^\nUndo a commit and make a topic branch out of it.\ngit branch topic/foo\ngit reset --hard HEAD~3\ngit checkout topic/foo"
  },
  {
    "objectID": "posts/Git.html#git-revert",
    "href": "posts/Git.html#git-revert",
    "title": "Local Git Commands",
    "section": "git revert",
    "text": "git revert\nrevert is a command that creates a new commit that undoes the changes made by a previous commit. This means that instead of deleting or altering past commits, git revert adds a new commit on top of the branch.\nWhen HEAD is on the merge commit,\ngit revert HEAD -m 1\ngit revert HEAD -m 2 \nThe number (index) of a parent can be checked with the command git cat-file -p HEAD."
  },
  {
    "objectID": "posts/GAN.html",
    "href": "posts/GAN.html",
    "title": "GAN",
    "section": "",
    "text": "There is an interactive playground available at GAN Lab. Feel free to explore it."
  },
  {
    "objectID": "posts/GAN.html#zero-sum-game-of-a-generator-and-a-discriminator",
    "href": "posts/GAN.html#zero-sum-game-of-a-generator-and-a-discriminator",
    "title": "GAN",
    "section": "Zero-sum game of a Generator and a Discriminator",
    "text": "Zero-sum game of a Generator and a Discriminator\nThe zero-sum property (if one gains, another loses) means that any result of a zero-sum situation is Pareto optimal which is also called a conflict game1.\nThe generator and discriminator engage in a zero-sum game, where the generator tries to produce data that fools the discriminator, while the discriminator aims to correctly identify real versus generated (fake) data. This interaction can be expressed with a payoff matrix.\n\n\n\n\n\n\n\n\\(D_\\text{good}\\)\n\n\n\\(D_\\text{poor}\\)\n\n\n\n\n\\(G_\\text{good}\\)\n\n\n\\(( 0, 0)\\)\n\n\n\\(( 1,-1)\\)\n\n\n\n\n\\(G_\\text{poor}\\)\n\n\n\\((-1, 1)\\)\n\n\n\\(( 0, 0)\\)\n\n\n\n\n\n\nThe payoff matrix shows all the combinations of what players can move. The gains for \\(G\\) and \\(D\\) in each state are denoted by tuples.\nThe best choice for \\(D\\), regardless of what \\(G\\) chooses, is \\(D_\\text{good}\\). When \\(G\\) chooses \\(G_\\text{good}\\), \\(D\\) can move from \\(-1\\) to \\(0\\), gaining \\(+1\\), and when \\(G\\) chooses \\(G_\\text{poor}\\), \\(D\\) can move from \\(0\\) to \\(1\\), also gaining \\(+1\\), making \\(D_\\text{good}\\) a dominant strategy. Same for \\(G\\), making \\(G_\\text{good}\\) a dominant strategy.\nThe solution for this game is choosing \\(D_\\text{good}\\) and \\(G_\\text{good}\\) which is considered as a Nash Equilibrium in GANs, maximizing both players’ gains.\nHowever, the question of whether a Nash Equilibrium exists in the GAN framework remains open. Read Farnia and Ozdaglar (2020) to find out more.\nSince the GAN framework can be modeled as a zero-sum game, we can also derive the same Nash Equilibrium using the second element of the tuples (\\(D\\)’s gain), which provides a more compact representation. This becomes the value function."
  },
  {
    "objectID": "posts/GAN.html#the-value-function",
    "href": "posts/GAN.html#the-value-function",
    "title": "GAN",
    "section": "The Value Function",
    "text": "The Value Function\n\\[\n\\min_G \\max_D V(D,G)\n= \\mathbb E_{\\mathbf x \\sim p_\\text{data}(\\mathbf x)}[\\log D(\\mathbf x)]\n+ \\mathbb E_{\\mathbf z \\sim p_\\mathbf{z}(\\mathbf z)}[\\log (1-D(G(\\mathbf z)))]\n\\]\nThe generator takes a latent variable \\(\\mathbf z\\) as input and outputs generated data \\(\\mathbf x\\). The discriminator takes data \\(\\mathbf x\\) as input and outputs a probability \\(y\\), representing whether the data is real (\\(1\\)) or fake (\\(0\\)).\n\\[\n\\begin{align*}\nG &:\\mathbf z \\to \\mathbf x \\\\\nD &:\\mathbf x \\to y\n\\end{align*}\n\\]\nThe value function (\\(V\\)) consists of two log-likelihood losses, each from a Bernoulli distribution: one representing the genuine data distribution and the other, the fake data distribution.\nLet \\(\\mathbf{x} \\sim p_\\text{data}(\\mathbf{x})\\) represent a sample drawn from the genuine data distribution. They are all labeled as \\(1\\). Same thing for the fake data \\(\\mathbf{z} \\sim p_\\mathbf{z}(\\mathbf{z})\\). They are all labeled as \\(0\\).\n\n\n\n\n\n\nNote\n\n\n\nDuring training, we will keep the number of samples for \\(\\mathbf{x}\\) and \\(\\mathbf{z}\\) the same.\n\n\n\nObjective of \\(D\\)\nThe Binary Cross-Entropy (BCE) is defined as follows.\n\\[\n\\mathcal L_\\text{BCE}(\\hat y, y)\n= - \\lbrace y \\log{\\hat y} + (1-y) \\log{(1-\\hat y)} \\rbrace\n\\]\nWe can try to optimize the model by decreasing the \\(\\mathcal L\\). Conversely, increasing \\(-\\mathcal L\\) resembles the same objective. When dealing with \\(D\\)’s loss, we use the latter approach.\nThe loss of \\(D\\) is calculated with negative BCE loss on both real and fake data distributions and are added together.\n\\[\n\\max_D V(D,G) =\n\\sum_{\\mathbf x}\n-\\mathcal L_\\text{BCE}(D(\\mathbf x), 1) +\n\\sum_{\\mathbf z}\n-\\mathcal L_\\text{BCE}(D(G(\\mathbf z)), 0)\n\\]\n\\(D\\) will try to maximize the value function \\(V(D,G)\\) thus, \\(\\theta_\\text{d}\\) is updated with gradient ascent.\n\n\nObjective of \\(G\\)\nIn \\(G\\)’s perspective, \\(G\\)’s objective is to fool \\(D\\) by creating more realistic data.\n\\[\n\\min_G V(G) =\n\\sum_{\\mathbf z}\n-\\mathcal L_\\text{BCE}(D(G(\\mathbf z)), 0) \\\\\n\\]\n\\(G\\) will try to minimize the value function \\(V(G)\\) thus, \\(\\theta_\\text{d}\\) is updated with gradient descent.\n\n\n\n\n\n\nUnifying the loss with respect to \\(V\\)\n\n\n\nNote that we are not using \\(\\mathcal L_\\text{BCE}(D(G(\\mathbf z)), 1)\\) as the value function for \\(G\\). In the context of zero-sum loss, we will try to unify the losses in terms of \\(V\\)."
  },
  {
    "objectID": "posts/GAN.html#theoretical-results",
    "href": "posts/GAN.html#theoretical-results",
    "title": "GAN",
    "section": "Theoretical Results",
    "text": "Theoretical Results\n\n\n\n\n\n\nFigure 1: Training GANs\n\n\n\nThe figure above is from Goodfellow et al. (2014). The genuine data distribution \\(p_\\text{data}\\) is represented by a black dotted line. and green denotes the generated distribution \\(p_\\text{g}\\), and lastly the color blue denotes the discriminated distribution,\nAs mentioned above, the output of \\(D\\) is the probability that the data is genuine, so the height of the blue bar represents the corresponding value between \\([0, 1]\\). The value of the blue distribution is one-half on \\(x\\), where \\(x\\) represents the intersection of the black and blue lines.\n\n\n\n\n\n\nNote\n\n\n\nThe results of this section are done in a non-parametric setting, e.g. we represent a model with infinite capacity by studying convergence in the space of probability density functions; \\(p_\\text{data}\\) and \\(p_\\text{g}\\).\n\n\nWe reach the global optimum of \\(V\\) when we approach optimal \\(D\\) and \\(G\\).\n\nOptimal \\(D\\)\nOptimal \\(D\\) can be obtained by maximizing \\(V\\). For any given \\(G\\), \\(D\\) will try it’s best to discriminate genuine data from the fake.\n\\[\\begin{align*}\nV(D,G)\n&= \\mathbb E_{\\mathbf x \\sim p_\\text{data}(\\mathbf x)}[\\log D(\\mathbf x)]\n+ \\mathbb E_{\\mathbf z \\sim p_\\mathbf{z}(\\mathbf z)}[\\log (1-D(G(\\mathbf z)))] \\\\\n\n&= \\int_\\mathbf{x} p_\\text{data}(\\mathbf x) \\log D(\\mathbf x) d \\mathbf x\n+ \\int_\\mathbf{z} p_\\mathbf{z}(\\mathbf z) \\log (1 - D(G(\\mathbf z))) d \\mathbf z \\\\\n\n&= \\int_\\mathbf{x} p_\\text{data}(\\mathbf x) \\log D(\\mathbf x) d \\mathbf x\n+ \\int_\\mathbf{x} p_\\text{g}(\\mathbf x) \\log (1 - D(\\mathbf x)) d \\mathbf x \\\\\n\n&= \\int_\\mathbf{x} p_\\text{data}(\\mathbf x) \\log D(\\mathbf x)\n                + p_\\text{g}(\\mathbf x) \\log (1 - D(\\mathbf x)) d \\mathbf x\n\\end{align*}\\]\nBy setting \\(p_\\text{data}(\\mathbf x)\\) as \\(a\\) and \\(p_\\text{g}(\\mathbf x)\\) as \\(b\\), the inner part of the integral can be expressed as the following.\n\\[\\begin{align*}\nf(y) &= a \\log y + b \\log (1-y) \\\\\n\\dfrac{d}{dy} f(y) &= \\dfrac{a}{y} - \\dfrac{b}{1-y} = 0 \\\\\n\\therefore y &= \\frac{a}{a+b}\n\\end{align*}\\]\nThe optimal \\(D\\) can be defined as follows.\n\\[\nD^*(\\mathbf x) = \\dfrac{p_\\text{data}(\\mathbf x)}{p_\\text{data}(\\mathbf x) + p_\\text{g}(\\mathbf x)}\n\\]\n\n\nOptimal \\(G\\)\nWith same \\(V\\), optimal \\(G\\) can be obtained by minimizing \\(V\\). We will find optimal \\(G\\) with respective to the optimal discriminator \\(D^*\\).\n\\[\\begin{align*}\nV(D^*,G)\n&= \\mathbb E_{\\mathbf x \\sim p_\\text{data}(\\mathbf x)}[\\log D^*(\\mathbf x)]\n+ \\mathbb E_{\\mathbf z \\sim p_\\mathbf{z}(\\mathbf z)}[\\log (1-D^*(G(\\mathbf z)))] \\\\\n\n&= \\mathbb E_{\\mathbf x \\sim p_\\text{data}(\\mathbf x)} \\left[\n  \\log \\dfrac{p_\\text{data}(\\mathbf x)}{p_\\text{data}(\\mathbf x) + p_\\text{g}(\\mathbf x)}\n\\right]\n+ \\mathbb E_{\\mathbf z \\sim p_\\mathbf{z}(\\mathbf z)} \\left[\n  \\log \\dfrac{p_\\text{g}(\\mathbf x)}{p_\\text{data}(\\mathbf x) + p_\\text{g}(\\mathbf x)}\n\\right] \\\\\n\n&= \\mathbb E_{\\mathbf x \\sim p_\\text{data}(\\mathbf x)} \\left[\n  \\log \\dfrac{2 \\ p_\\text{data}(\\mathbf x)}{p_\\text{data}(\\mathbf x) + p_\\text{g}(\\mathbf x)}\n\\right]\n+ \\mathbb E_{\\mathbf z \\sim p_\\mathbf{z}(\\mathbf z)} \\left[\n  \\log \\dfrac{2 \\ p_\\text{g}(\\mathbf x)}{p_\\text{data}(\\mathbf x) + p_\\text{g}(\\mathbf x)}\n\\right]\n- \\log 4 \\\\\n\n&= \\mathbb E_{\\mathbf x \\sim p_\\text{data}(\\mathbf x)} \\left[\n  \\log \\dfrac{p_\\text{data}(\\mathbf x)}{\\dfrac{p_\\text{data}(\\mathbf x) + p_\\text{g}(\\mathbf x)}{2}}\n\\right]\n+ \\mathbb E_{\\mathbf z \\sim p_\\mathbf{z}(\\mathbf z)} \\left[\n  \\log \\dfrac{p_\\text{g}(\\mathbf x)}{\\dfrac{p_\\text{data}(\\mathbf x) + p_\\text{g}(\\mathbf x)}{2}}\n\\right]\n- \\log 4\n\\\\\n\n&= D_\\text{KL} \\left( p_\\text{data}(\\mathbf x) \\bigg\\| \\dfrac{p_\\text{data}(\\mathbf x) + p_\\text{g}(\\mathbf x)}{2} \\right)\n+ D_\\text{KL} \\left( p_\\text{g}(\\mathbf x) \\bigg\\| \\dfrac{p_\\text{data}(\\mathbf x) + p_\\text{g}(\\mathbf x)}{2} \\right) - \\log 4 \\\\\n\n&= 2 \\ \\mathrm{JSD}(p_\\text{data}(\\mathbf x) \\| p_\\text{g}(\\mathbf x)) - \\log 4 \\\\\n\n&\\geq -\\log 4 \\\\[20pt]\n\n\\min_{G} V(D^*, G) &= -\\log 4 \\iff p_\\text{data} = p_\\text{g} \\\\\n\nV(D^*,G^*) &= -\\log4\n\\end{align*}\\]\n\n\n\n\n\n\nDoes the order of \\(\\min\\), \\(\\max\\) matter?\n\n\n\nYes, it does.\nMathematically, \\(\\min_G \\max_D V(D, G)\\) is the same as \\(\\min_G (\\max_D V(D, G))\\).\nWe try to solve from the inner parentheses.\nIn GAN’s perspective, as long as \\(D\\) tries its best to discriminate the two distributions, the best strategy for \\(G\\) is to mimic \\(p_\\text{data}\\) as closely as possible."
  },
  {
    "objectID": "posts/GAN.html#footnotes",
    "href": "posts/GAN.html#footnotes",
    "title": "GAN",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWikipedia - Zero-sum game↩︎"
  },
  {
    "objectID": "posts/DifferentialEntropy.html",
    "href": "posts/DifferentialEntropy.html",
    "title": "Differential Entropy",
    "section": "",
    "text": "What is entropy? Randomness? Compression lower bound?\nIn this post, let’s think of entropy as a scalar function of the random variable \\(X\\). It is also correct to say it is a scalar function of a distribution.\nLet’s first look at the definition of entropy.\n\\[\nH(X) = \\mathbb E \\left[ \\log \\dfrac{1}{p_X(X)} \\right] = \\sum_{x \\in \\mathcal X} p_X(x) \\log \\dfrac{1}{p_X(x)}\n\\]\nThere’s nothing particularly special here. We discussed this in the previous\npost. We should be able to apply this concept to all types of\ndistributions — not just probability mass functions (PMFs), but also probability density functions (PDFs).\nCheck this lecture note from Duke to find out more.\nDifferential entropy is defined as follows.\n\\[\nh(X) = \\mathbb E \\left[ \\log \\dfrac{1}{f_X(X)} \\right] = \\int_{\\mathcal X} f_X(x) \\log \\dfrac{1}{f_X(x)} dx\n\\]\n\\(h\\) of PDFs are initially derived from \\(H\\) by binning the continuous random variable \\(X\\) into \\(X^\\Delta\\). Let’s see how it works."
  },
  {
    "objectID": "posts/DifferentialEntropy.html#proof",
    "href": "posts/DifferentialEntropy.html#proof",
    "title": "Differential Entropy",
    "section": "Proof",
    "text": "Proof\nFirst, prepare an arbitrary PDF. In this example, we are using \\(\\mathcal N(x;0,1)\\).\n\n\n\n\n\n\n\n\n\nWe set \\(\\Delta\\) to bin the continuous RV \\(X\\).\n\n\n\n\n\n\n\n\n\nBy mean value theorem (MVT), for continuous \\(f\\):\n\\[\n\\exists x_i \\in [i\\Delta, (i+1)\\Delta] :\nf_X(x_i) \\Delta = \\int_{i\\Delta}^{(i+1)\\Delta} f_X(x) dx\n\\]\n\n\n\n\n\n\n\n\n\n\\[\np_{X^\\Delta}(x_i) \\triangleq f_X(x_i) \\Delta\n\\]\n\n\n\n\n\n\n\n\n\n\\[\\begin{align*}\nH(X^\\Delta)\n&= \\sum_i p_{X^\\Delta}(x_i) \\log \\dfrac{1}{p_{X^\\Delta}(x_i)} \\\\\n&= \\sum_i f_X(x_i) \\Delta \\log \\dfrac{1}{f_X(x_i) \\Delta} \\\\\n&= \\sum_i f_X(x_i) \\Delta \\log \\dfrac{1}{f_X(x_i)} + \\sum_i f_X(x_i) \\Delta \\log \\dfrac{1}{\\Delta} \\\\\n&\\approx \\int_{\\mathcal X} f_X(x) \\log \\dfrac{1}{f_X(x)} dx + \\log \\dfrac{1}{\\Delta} \\\\[20pt]\n\nh(X) &= \\lim_{\\Delta \\to 0} \\left( H(X^\\Delta) - \\log \\dfrac{1}{\\Delta} \\right)\n\\end{align*}\\]"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Posts",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\n.kube/config\n\n\nwith KubeContext\n\n\n2 min\n\n\n\nKubernetes\n\n\n\n\n\n\n\nShane Oh\n\n\nAug 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nBinary Heap\n\n\nFor better priority queuing\n\n\n12 min\n\n\n\nAlgorithms\n\n\n\n\n\n\n\nShane Oh\n\n\nSep 7, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nDifferential Entropy\n\n\nEntropy for PDFs\n\n\n3 min\n\n\n\nEntropy\n\n\nInformation Theory\n\n\n\n\n\n\n\nShane Oh\n\n\nOct 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nEntropy\n\n\nThe lower bound of \\(\\bar \\lambda\\)\n\n\n4 min\n\n\n\nInformation Theory\n\n\nData Compression\n\n\n\n\n\n\n\nShane Oh\n\n\nSep 14, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nGAN\n\n\nWhich Comes First? Generator or Discriminator?\n\n\n7 min\n\n\n\nML\n\n\nGenerative Models\n\n\n\n\n\n\n\nShane Oh\n\n\nSep 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nGeometric Seuqnece\n\n\nAdding up terms in a sequence with a pattern\n\n\n1 min\n\n\n\nMath\n\n\n\n\n\n\n\nShane Oh\n\n\nAug 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGit Prompt\n\n\nCheck the branch you are working on\n\n\n1 min\n\n\n\nGit\n\n\n\n\n\n\n\nShane Oh\n\n\nApr 18, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGo Concurrency\n\n\nChannel, waitgroup, mutex\n\n\n2 min\n\n\n\nGo\n\n\n\n\n\n\n\nShane Oh\n\n\nSep 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHuffman Coding\n\n\nLossless data compression\n\n\n11 min\n\n\n\nInformation Theory\n\n\nData Compression\n\n\nAlgorithms\n\n\n\n\n\n\n\nShane Oh\n\n\nApr 14, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nIngress\n\n\nLoadBalancer and Beyond\n\n\n4 min\n\n\n\nK8s\n\n\n\nhttps://docs.nginx.com/images/icons/NGINX-Ingress-Controller-product-icon.svg\n\n\n\nShane Oh\n\n\nFeb 4, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nInternally Dividing Point\n\n\n\n\n\n1 min\n\n\n\nMath\n\n\n\n\n\n\n\nShane Oh\n\n\nSep 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nJensen’s Inequality\n\n\n\n\n\n1 min\n\n\n\nMath\n\n\nProbability Theory\n\n\n\n\n\n\n\nShane Oh\n\n\nSep 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nKubernetes Cluster with Raspberry Pi\n\n\nFrom zero to hero!\n\n\n10 min\n\n\n\nKubernetes\n\n\n\nInspired by NetworkChuck\n\n\n\nShane Oh\n\n\nOct 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLocal Git Commands\n\n\n\n\n\n7 min\n\n\n\nGit\n\n\n\n\n\n\n\nShane Oh\n\n\nApr 14, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nMeasuring Distributions\n\n\nGibbs’ inequality and more!\n\n\n4 min\n\n\n\nEntropy\n\n\nInformation Theory\n\n\n\nJust like Huffman coding’s optimality, we can discuss entropy’s optimality using Gibbs’ inequality\n\n\n\nShane Oh\n\n\nOct 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTmux\n\n\nTerminal multiplexer\n\n\n5 min\n\n\n\nLinux\n\n\n\n\n\n\n\nShane Oh\n\n\nJun 5, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTraefik dashboard with Helm\n\n\n\n\n\n1 min\n\n\n\nKubernetes\n\n\nHelm\n\n\n\n\n\n\n\nShane Oh\n\n\nFeb 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nVibration Analysis\n\n\n\n\n\n1 min\n\n\n\nVibration Analysis\n\n\n\n\n\n\n\nShane Oh\n\n\nNov 23, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Made with ♥ by Shane Oh"
  },
  {
    "objectID": "posts/BinaryHeap.html",
    "href": "posts/BinaryHeap.html",
    "title": "Binary Heap",
    "section": "",
    "text": "Check out a video by Abdul Bari."
  },
  {
    "objectID": "posts/BinaryHeap.html#represent-a-binary-tree-in-an-array",
    "href": "posts/BinaryHeap.html#represent-a-binary-tree-in-an-array",
    "title": "Binary Heap",
    "section": "Represent a binary tree in an array",
    "text": "Represent a binary tree in an array\n\n\n\n\n\nflowchart TB\n  A(1: A) --- B(2: B)\n  A --- C(3: C)\n  B --- D(4: D)\n  B --- E(5: E)\n  C --- F(6: F)\n  C --- G(7: G)\n\n\n\n\n\n\n\n  \n  A\n  B\n  C\n  D\n  E\n  F\n  G\n\n  idx\n  1\n  2\n  3\n  4\n  5\n  6\n  7\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nTo represent a binary tree in an array, you can follow these rules:\n\nIf the root of the tree is at index 1 &lt;- easier to remember\nFor a node at index \\(i\\):\n\nThe left child is at index \\(2i\\).\nThe right child is at index \\(2i+1\\).\nThe parent is at index \\(\\lfloor \\frac{i}{2} \\rfloor\\).\n\nIf the root of the tree is at index 0 &lt;- when implementing\nFor a node at index \\(i\\):\n\nThe left child is at index \\(2i+1\\).\nThe right child is at index \\(2i+2\\).\nThe parent is at index \\(\\lfloor \\frac{i - 1}{2} \\rfloor\\).\n\n\n\n\nThe definition of an (almost) complete binary tree becomes clearer when we represent tree structure as an array. We should not allow any null values between the elements.\nNow you may be thinking about the difference between binary trees and heaps. Actually, while all heaps are binary trees, not all binary trees are heaps. You must fulfill the heap property. So what is it?"
  },
  {
    "objectID": "posts/BinaryHeap.html#heap-property",
    "href": "posts/BinaryHeap.html#heap-property",
    "title": "Binary Heap",
    "section": "Heap property",
    "text": "Heap property\n\n  \n    Tree\n    \n      Binary tree\n      \n        Almost complete binary tree\n        \n          Heap\n          \n            Min-heap / Max-heap\n          \n        \n      \n    \n  \n\n\n\nThe heap property dictates the relationship between a parent node and its children in a binary tree. It can be defined in two ways, leading to two different types of heaps:\n\nMin-heap property \\[A[\\lfloor \\frac{i}{2} \\rfloor] \\leq A[i]\\]\nMax-heap property \\[A[\\lfloor \\frac{i}{2} \\rfloor] \\geq A[i]\\]\n\nI find defining the property with the relationship of a current node \\(i\\) and the parent node \\(\\lfloor \\dfrac{i}{2} \\rfloor\\) is more simple (since it can handle the root condition).\nIf you have an array \\(A\\) with no null values between elements, you are already satisfying the almost complete binary tree property and are halfway ready to be a heap structure. How cool is that!\nThe remaining half of the process is called build-heap. We build-heap by heapifying \\(n\\) times.\nFrom now on, we will take a close look at the max-heap since the min-heap and max-heap are basically the same."
  },
  {
    "objectID": "posts/BinaryHeap.html#heapify",
    "href": "posts/BinaryHeap.html#heapify",
    "title": "Binary Heap",
    "section": "Heapify",
    "text": "Heapify\nCheck out the video by Techdose helps!\n\n\n\n\n\nflowchart TB\n  A(  ) -.- 10\n  A(  ) -.- B(  )\n  10 --- 8\n  10 --- 12\n  8 -.- C(  )\n  8 -.- D(  )\n  12 -.- E(  )\n  12 -.- F(  )\n\n\n\n\n\n\nLet’s examine the tree above (with node 10 as root). Assert that the subtrees under node 10 are max-heaps. By recursively sifting down (similar to bubble sorting) on node 10, the entire tree will eventually become a max-heap.\nThe time complexity of heapifying is the same as the height of the heapifying index. Thankfully, the tree is balanced from the very start, which makes it \\(O(\\log n)\\). Obvious, right?"
  },
  {
    "objectID": "posts/BinaryHeap.html#build-heap",
    "href": "posts/BinaryHeap.html#build-heap",
    "title": "Binary Heap",
    "section": "Build heap",
    "text": "Build heap\nThanks again for the video!\nLet’s transform an arbitrary array \\(A\\) into a heap using the build-heap process.\n\\[\\begin{align*}\n  A &\\quad\n  \\begin{bmatrix}\n    2 & 12 & 5 & 15 & 16 & 2 & 6 & 9 & 1 & 4\n  \\end{bmatrix} \\\\\n\n  \\text{Build-Max-Heap}(A) &\\quad\n  \\begin{bmatrix}\n    16 & 15 & 6 & 9 & 12 & 2 & 5 & 2 & 1 & 4\n  \\end{bmatrix}\n\\end{align*}\\]\nAt first glance, it might seem intuitive that repeatedly heapifying the array \\(n\\) times, starting from the right (or bottom), will transform \\(A\\) into a heap.\nWould it be surprising to you if I told you that the time complexity of the build-heap algorithm is actually \\(O(n)\\) instead of \\(O(n \\log n)\\)?\n\n\nmaxheapify.go\n\n// MaxHeap constructs a max-heap from an unordered array\n// `i` starts from 0 in this code\n// We are basically bubble sorting from node `i` to the leaf node\n// while iterating `i` from n to 0.\nfunc BuildMaxHeap(arr []int, n int) {\n    // Start from the last non-leaf node and heapify each node\n1    for i := n/2 - 1; i &gt;= 0; i-- {\n        MaxHeapify(arr, n, i)\n    }\n}\n\n// MaxHeapify ensures the subtree rooted at index i is a max-heap\n//      i\n//    /   \\\n// left   right\nfunc MaxHeapify(arr []int, n, i int) {\n    largest := i       // Initialize largest as root\n    left := 2*i + 1    // left child index\n    right := 2*i + 2   // right child index\n\n    // If left child is larger than root\n    if left &lt; n && arr[left] &gt; arr[largest] {\n        largest = left\n    }\n\n    // If right child is larger than the largest so far\n    if right &lt; n && arr[right] &gt; arr[largest] {\n        largest = right\n    }\n\n    // If largest is not root\n    if largest != i {\n        arr[i], arr[largest] = arr[largest], arr[i]  // Swap\n\n        // Recursively heapify the affected subtree\n        MaxHeapify(arr, n, largest)\n    }\n}\n\n\n1\n\nThe for loop can be iterated from n to 0. However, since half of the elements (which are leaf nodes) are already part of a heap, we can start from the node that is not a leaf.\n\n\n\n\n\n\n\n\nLevels and heights of binary trees\n\n\n\nLevel 0                  1                  Height 3\n                        / \\                         \nLevel 1          2               3          Height 2\n                / \\             / \\                 \nLevel 2      4       5       6       7      Height 1\n            / \\     / \\     / \\     / \\             \nLevel 3    8   9  10   11 12   13 14   15   Height 0\nTry to imagine a complete binary tree with a large number of levels. Pick any level you desire in between and set it as \\(l\\).\n\nThe indices of the first elements at each level are \\(2^l\\) and the level of a certain index is \\(\\lfloor \\log_{2} i \\rfloor\\).\nThere are \\(2^{l}-1\\) nodes in the whole tree just before level \\(l\\).\nThere are \\(2^{l}\\) nodes at level \\(l\\).\nThere are \\(2^{l+1}\\) nodes at the next level, \\(l+1\\), which is twice as many.\nAt height \\(h\\), there are a maximum of \\(\\lceil \\frac{N}{2^{h+1}} \\rceil\\) nodes.\n\n\n\nThe nodes at height \\(h\\) needs to be heapified by sifting down \\(h\\) times and there are \\(\\lceil \\frac{N}{2^{h+1}} \\rceil\\) nodes max at each height \\(h\\) which makes,\n\\[\n\\begin{align*}\n\\sum_{h=0}^{\\lfloor \\log_2 N \\rfloor} \\lceil \\dfrac{N}{2^{h+1}} \\rceil O(h)\n&&lt; O \\left( \\sum_{h=0}^{\\infty} \\dfrac{N}{2^{h+1}} C h \\right) \\\\\n&= O \\left( \\dfrac{CN}{2} \\sum_{h=0}^{\\infty} \\dfrac{h}{2^{h}} \\right) \\\\\n&= O \\left( \\dfrac{CN}{2} 2 \\right) \\\\\n&= O(N)\n\\end{align*}\n\\]\nThe talor series is useful when explaining this. Check out the [post] if you are interested.\n\n\n\n\n\n\nWhat is the range of leaf nodes?\n\n\n\nThe parent of the last element can be considered the last node that is not a leaf node.\n\\[\nA[\\lfloor \\dfrac{n}{2} \\rfloor + 1:n]\n\\]\n\n\nCongratulations! You now have a beautiful max-heap ready. Let’s utilize this as a priority queue."
  },
  {
    "objectID": "posts/BinaryHeap.html#inserting-and-popping-elements-in-the-queue",
    "href": "posts/BinaryHeap.html#inserting-and-popping-elements-in-the-queue",
    "title": "Binary Heap",
    "section": "Inserting and popping elements in the queue",
    "text": "Inserting and popping elements in the queue\nInsert from the right, pop from the left.\nInserting from the right helps us to maintain the almost complete binary tree property, but the max-heap property is broken.\n\\[\\begin{align*}\n  A_\\text{max-heap} &\\quad\n  \\begin{bmatrix}\n    16 & 15 & 6 & 9 & 12 & 2 & 5 & 2 & 1 & 4\n  \\end{bmatrix}\\\\\n\n  A_\\text{broken-max-heap} &\\quad\n  \\begin{bmatrix}\n    16 & 15 & 6 & 9 & 12 & 2 & 5 & 2 & 1 & 4 & 100\n  \\end{bmatrix}\\\\\n\n  &\\quad\n  \\begin{bmatrix}\n    16 & 15 & 6 & 9 & 100 & 2 & 5 & 2 & 1 & 4 & 12\n  \\end{bmatrix}\\\\\n\n  &\\quad\n  \\begin{bmatrix}\n    16 & 100 & 6 & 9 & 15 & 2 & 5 & 2 & 1 & 4 & 12\n  \\end{bmatrix}\\\\\n\n  A_\\text{max-heap} &\\quad\n  \\begin{bmatrix}\n    100 & 16 & 6 & 9 & 15 & 2 & 5 & 2 & 1 & 4 & 12\n  \\end{bmatrix}\\\\\n\\end{align*}\\]\nThe solution is to check the integrity from the inserted leaf node to the root. Simply compare with the parent node and propagate upward to the top. In the array representation, it seems like hopping to the left for \\(\\log n\\) times.\nPopping is done by removing the root and replacing it with the last leaf node. To preserve the max-heap property, we propagate downward from the root to the bottom.\n\\[\\begin{align*}\n  A_\\text{max-heap} &\\quad\n  \\begin{bmatrix}\n    100 & 16 & 6 & 9 & 15 & 2 & 5 & 2 & 1 & 4 & 12\n  \\end{bmatrix}\\\\\n\n  A_\\text{broken-max-heap} &\\quad\n  \\begin{bmatrix}\n    12 & 16 & 6 & 9 & 15 & 2 & 5 & 2 & 1 & 4\n  \\end{bmatrix}\\\\\n\n  &\\quad\n  \\begin{bmatrix}\n    16 & 12 & 6 & 9 & 15 & 2 & 5 & 2 & 1 & 4\n  \\end{bmatrix}\\\\\n\n  A_\\text{max-heap} &\\quad\n  \\begin{bmatrix}\n    16 & 15 & 6 & 9 & 12 & 2 & 5 & 2 & 1 & 4\n  \\end{bmatrix}\\\\\n\n\\end{align*}\\]\nNotice that the root node always holds the maximum value of the entire tree. This characteristic enables sorting; you simply keep popping the root until the heap is empty."
  },
  {
    "objectID": "posts/BinaryHeap.html#heap-sort",
    "href": "posts/BinaryHeap.html#heap-sort",
    "title": "Binary Heap",
    "section": "Heap sort",
    "text": "Heap sort\nWhy do we need to create a dedicated paragraph for sorting when it is so straightforward? There is a fun little idea behind heap sorting in an array that makes it more elegant.\n\n\nheapsort.go\n\nfunc HeapSort(arr []int, n int) {\n1    BuildMaxHeap(arr)\n2    for m := n - 1; m &gt;= 0; m-- {\n3        arr[0], arr[m] = arr[m], arr[0]\n        MaxHeapify(arr, m, 0)\n    }\n}\n\n\n1\n\nFirst, create a max-heap.\n\n2\n\nInstead of popping and stacking the elements into a new empty array, we utilize the original array. After popping, there is a spare index because the size of the heap is reduced.\n\n3\n\nBy marking the end of the max-heap with m, we can swap the root value with the leaf at the very end. The popped value will be stacked from the end of the array, and eventually, the array will become a sorted array in ascending order."
  },
  {
    "objectID": "posts/Entropy.html",
    "href": "posts/Entropy.html",
    "title": "Entropy",
    "section": "",
    "text": "I highly recommend taking a look at the Huffman Coding post first. Huffman coding provides an optimal compression solution for a given data distribution, whereas Shannon-Fano coding does not.\nIt may be easier for us to first learn Huffman coding (a bottom-up approach to building the tree) in the algorithms class and then move on to Shannon-Fano coding (a top-down approach).\nTake a look at the video."
  },
  {
    "objectID": "posts/Entropy.html#recap-of-huffman-coding",
    "href": "posts/Entropy.html#recap-of-huffman-coding",
    "title": "Entropy",
    "section": "Recap of Huffman coding",
    "text": "Recap of Huffman coding\nIn the last post, we derived the average codeword length of Huffman coding.\n\\[\n\\bar \\lambda = \\mathbb E [ \\lambda ]\n= \\sum_{i=1}^N p(x_i) \\lambda_i\n= \\sum_{i=1}^N p(x_i) \\left\\lceil \\log_2 \\dfrac{1}{p(x_i)} \\right\\rceil\n\\]\nOne thing we had a hard time deriving was \\(\\lambda\\). We needed to check the frequency (or probability) of each character and aggregate them into a binary tree structure. After that, we traced the path from the root node to each leaf, encoding every character into a binary codeword. Finally, we mapped all of the codewords to the function len to obtain our most desired value, the length of each codeword.\nThe value \\(\\lambda\\) can be interpreted as the number of bits (information) required to losslessly represent an arbitrary group (such as a character or color) within the given data. As you can feel from the word group, we were working on a discrete random variable.\nWe can guarantee the optimality of \\(\\lambda\\) only with the given data distribution. If different data is provided, the frequency (probability) changes, causing the entire Huffman tree to differ from before.\n\n\n\n\n\n\nWhat if we provide a data only with the most frequent character from the existing Huffman tree?\n\n\n\nThis will reduce \\(\\bar \\lambda\\) exceptionally but not with an optimal length. If all characters are the same, the optimal length for the given data will be 0 because the leaf node will also be the root."
  },
  {
    "objectID": "posts/Entropy.html#entropy-as-a-lower-bound-of-bar-lambda",
    "href": "posts/Entropy.html#entropy-as-a-lower-bound-of-bar-lambda",
    "title": "Entropy",
    "section": "Entropy as a lower bound of \\(\\bar \\lambda\\)",
    "text": "Entropy as a lower bound of \\(\\bar \\lambda\\)\nWhat if I say we don’t need all of the cumbersome processes mentioned above? Take a look at the formula below.\n\\[\nH(X) = \\mathbb E[I(X)] = \\sum_{i=1}^N p(x_i) \\log_2 \\dfrac{1}{p(x_i)}\n\\]\nIs entropy just another form of average codeword length?\nThe answer is no. This works as the theoretical lower bound for any data distribution (both discrete and continuous) when compressing. We can not get below this bound if we are performing a lossless compression.\nWe can see that the \\(\\lambda_i\\) has turned into a \\(\\log\\) form with a probability. Since \\(x_i\\) is the only parameter, we can define \\(H\\) as a scalar funciton for any random vaiable \\(X\\). As the probability of \\(x_i\\) increases we can compress the information into a smaller, more compact \\(I(x_i)\\).\nWe can set the theoretical lower bound for \\(\\bar \\lambda\\) as below.\n\\[\nH(X) \\leq \\bar \\lambda\n\\]\nLet’s prove this!"
  },
  {
    "objectID": "posts/Entropy.html#proofing-the-lower-bound-of-bar-lambda",
    "href": "posts/Entropy.html#proofing-the-lower-bound-of-bar-lambda",
    "title": "Entropy",
    "section": "Proofing the lower bound of \\(\\bar \\lambda\\)",
    "text": "Proofing the lower bound of \\(\\bar \\lambda\\)\nWe need to know some basics of Jensen’s inequality and Kraft-McMillan inequality to prove this. Check out the Jensen’s inequality, Kraft-McMillan inequality posts to see more.\n\\[\n\\begin{align*}\nH(X) - \\bar{\\lambda}\n&= \\sum_{i=1}^N \\left( p(x_i) \\dfrac{1}{\\log_2 p(x_i)} - p(x_i) \\lambda_i \\right) \\\\[10pt]\n&= \\sum_{i=1}^N p(x_i) \\left( \\dfrac{1}{\\log_2 p(x_i)} - \\lambda_i \\right) \\\\[10pt]\n&= \\sum_{i=1}^N p(x_i) \\left( \\dfrac{1}{\\log_2 p(x_i)} \\log_2 2^{-\\lambda_i} \\right) \\\\[10pt]\n&= \\sum_{i=1}^N p(x_i) \\log_2 \\left( \\dfrac{2^{-\\lambda_i}}{p(x_i)} \\right)\n   \\leq \\log_2 \\sum_{i=1}^N p(x_i) \\dfrac{2^{-\\lambda_i}}{p(x_i)} &\\cdots \\text{Jensen's inequality} \\\\[10pt]\n&= \\log_2 \\sum_{i=1}^N 2^{-\\lambda_i} \\leq \\log_2 1 &\\cdots \\text{Kraft-McMillan inequality} \\\\[10pt]\n&= 0\n\\end{align*}\n\\]\nWell, that’s it! For fun, let’s take a look at the graph below.\n\n\n\n\n\n\nFigure 1: Lower bound of lambda bar\n\n\n\nThink \\(\\varphi(x)\\) as \\(-\\log_2 p(x)\\). You can clearly see that entropy (the blue cross) is working as a lower bound.\nWe have not talked about the upper bound of \\(\\bar \\lambda\\).\n\\[\nH(X) \\leq \\bar \\lambda \\lt H(X)+1\n\\]\nThe red and blue crosses are the weighted averages of each function’s outputs. Try ripping the crosses apart from each other. Can you make it greater than 1? Probably not. Infinitely approaching all \\(p(x_i)\\) to values near powers of 2 from the left-hand side is the most probable way, but you won’t be able to get there.\nIf you do get there, it means you are allowing all \\(x_i\\) to have an extra bit, which is not optimal in the first place."
  },
  {
    "objectID": "posts/GeometricSequence.html",
    "href": "posts/GeometricSequence.html",
    "title": "Geometric Seuqnece",
    "section": "",
    "text": "When adding up terms in a sequence with a specific pattern, such as a geometric sequence, using a formula or recognizing a pattern can make the process much easier.\nLet’s see how it works.\n\\[\na, ar, ar^2, ar^3, \\cdots, ar^n\n\\]\nThe sequence above is an arbitrary geometric sequence, where each character denotes the following:\n\n\\(a\\): the first term\n\\(r\\): the common ratio\n\nThe sum from the first term to the n-th term can be calculated using the following formula.\n\\[\n\\begin{align*}\nS_n &= a + ar + ar^2 + \\cdots + ar^{n-1} \\\\\nrS_n &= ar + ar^2 + ar^3 \\cdots + ar^n \\\\\nrS_n - S_n &= ar^n - a \\\\\nS_n &= \\dfrac{a(r^n - 1)}{r-1}\n\\end{align*}\n\\]\nThis formula can be easily seen when counting nodes in a complete binary tree or calculating the moving average of a gradient using the momentum."
  },
  {
    "objectID": "posts/GitPrompt.html",
    "href": "posts/GitPrompt.html",
    "title": "Git Prompt",
    "section": "",
    "text": "Download the git-prompt.sh with the curl command.\ncurl https://raw.githubusercontent.com/git/git/master/contrib/completion/git-prompt.sh -o ~/.git-prompt.sh\nThen add the following lines to the rc files depending on your environment.\n\n\n.zshrc\n\nsource ~/.git-prompt.sh\nsetopt PROMPT_SUBST\nPS1='%n@%m %c%F{green}$(__git_ps1 \" (%s)\")%f \\$ '\n\n\n\n.bashrc\n\nsource ~/.git-prompt.sh\nexport GIT_PS1_SHOWDIRTYSTATE=1\nexport PS1='\\[\\e[0;32m\\]\\u@\\h\\[\\e[0m\\] \\[\\e[0;34m\\]\\W\\[\\e[0m\\]\\[\\e[0;33m\\]$(__git_ps1 \" (%s)\")\\[\\e[0m\\] \\$ '"
  },
  {
    "objectID": "posts/HuffmanCoding.html",
    "href": "posts/HuffmanCoding.html",
    "title": "Huffman Coding",
    "section": "",
    "text": "Thanks to Pizzey Technology for the wonderful video."
  },
  {
    "objectID": "posts/HuffmanCoding.html#concepts",
    "href": "posts/HuffmanCoding.html#concepts",
    "title": "Huffman Coding",
    "section": "Concepts",
    "text": "Concepts\nHuffman coding is a type of variable-length prefix coding that assigns shorter codes to more frequent symbols and longer codes to less frequent symbols. Formal definitions aren’t very useful when dealing with other concepts, in this case, entropy.\nWell, keep this in mind: lossless.\nHuffman coding is one of the lossless compression methods. In terms of compression, you cannot compress data smaller than the limit defined by entropy.\nHuffman is a bottom-up approach to compression which is optimal, while Shannon entropy defines the theoretical limit, a lower bound.\nExamples first."
  },
  {
    "objectID": "posts/HuffmanCoding.html#ascii",
    "href": "posts/HuffmanCoding.html#ascii",
    "title": "Huffman Coding",
    "section": "ASCII",
    "text": "ASCII\nASCII is a character encoding developed in the ’60s by ANSI. It uses 7 bits for character representation. However, in modern computing, characters are stored in bytes (8 bits) for compatibility reasons.\nLet’s take a look at the 8-bit encoded sentence.\n\n\nAN APPLE A DAY KEEPS THE DOCTOR AWAY\n\n01000001 01001110 00100000 01000001 01010000 01010000 01001100 01000101 \n00100000 01000001 00100000 01000100 01000001 01011001 00100000 01001011 \n01000101 01000101 01010000 01010011 00100000 01010100 01001000 01000101 \n00100000 01000100 01001111 01000011 01010100 01001111 01010010 00100000 \n01000001 01010111 01000001 01011001 \n\n288 bits / 36.0 bytes\ncompression rate: 0.0%\n\n\nYou can easily determine the total number of bits in this sentence by simply multiplying the number of characters (including spaces) by the fixed encoding size."
  },
  {
    "objectID": "posts/HuffmanCoding.html#compress-it",
    "href": "posts/HuffmanCoding.html#compress-it",
    "title": "Huffman Coding",
    "section": "Compress it!",
    "text": "Compress it!\nThe more frequently a character appears, the shorter its encoded length becomes.\nThe phrase AN APPLE A DAY KEEPS THE DOCTOR AWAY uses A to rhyme which makes the example more fun.\n\nHuffman tree\nWe build the tree from the bottom using the less frequent characters. Eventually, the less frequent ones are placed at deeper levels. The deeper a character is, the longer the traversal route from the root, which results in a longer encoding length.\nCheck the code below.\n\nfrom collections import Counter\n\nclass Node:\n    def __init__(self, char='', freq=0, left=None, right=None):\n        self.char  = char\n        self.freq  = freq\n        self.left  = left\n        self.right = right\n    \n    @property\n    def is_leaf(self):\n        return self.left is None and self.right is None\n    \n    def __str__(self):\n        if self.is_leaf:\n            return f\"'{self.char}': {self.freq}\"\n        return str(self.freq)\n    \n    def __lt__(self, other):\n        return self.freq &lt; other\n\n    def __gt__(self, other):\n        return self.freq &gt; other\n        \nclass HuffmanTree:\n    def __init__(self, freq_table):\n        self.freq_table = dict(freq_table)\n        self.encoded_table = {}\n        self.root = None\n\n        self.build()\n        self.encode()\n\n    @property\n    def l_bar(self):\n        total = 0\n        for char, freq in self.freq_table.items():\n            total += len(self.encoded_table[char]) * freq\n        return total / sum(self.freq_table.values())\n    \n    def build(self):\n        nodes = [Node(char, freq) for char, freq in self.freq_table.items()]\n        while len(nodes) &gt; 1:\n3            node1 = nodes.pop(nodes.index(min(nodes)))\n            node2 = nodes.pop(nodes.index(min(nodes)))\n            node  = Node(freq=node1.freq+node2.freq,\n                         left=node2,\n                         right=node1)\n            nodes.append(node)\n            self.root = node\n    \n    def encode(self):\n        def dfs(node, path=''):\n1            if node.is_leaf:\n                self.encoded_table[node.char] = path\n                return\n2            dfs(node.left,  path+'0')\n            dfs(node.right, path+'1')\n\n        dfs(self.root)\n\n\n1\n\nCharacters are only at the leaf nodes. This property ensures that each encoded value is not a substring of another and keeps the unique decodability. This is also called as the prefix-free coding.\n\n2\n\nUse 0 for the left and 1 for the right. The path from the root to the leaf node represents the encoded result.\n\n3\n\nAs the function min returns the index of the first occurring minimum value (node.freq) from the list nodes, the built tree is not unique but preserves optimality.\n\n\n\n\n\n\n\n\n\ngraph RL\n140297927054352[36]\n140297927054352 -- 0 --&gt; 140297928845648\n140297927054352 -- 1 --&gt; 140297927050256\n140297928845648[21]\n140297928845648 -- 0 --&gt; 140297928847952\n140297928845648 -- 1 --&gt; 140297928845968\n140297927050256[15]\n140297927050256 -- 0 --&gt; 140297928847440\n140297927050256 -- 1 --&gt; 140297928846096\n140297928847952[13]\n140297928847952 -- 0 --&gt; 140297927012304\n140297928847952 -- 1 --&gt; 140297927008656\n140297928845968[8]\n140297928845968 -- 0 --&gt; 140297928844304\n140297928845968 -- 1 --&gt; 140297928835536\n140297928847440[8]\n140297928847440 -- 0 --&gt; 140297928836048\n140297928847440 -- 1 --&gt; 140297928849168\n140297928846096[7]\n140297928846096 -- 0 --&gt; 140297927011408\n140297928846096 -- 1 --&gt; 140297927014160\n140297927012304[' ': 7]\n140297927008656['A': 6]\n140297928844304[4]\n140297928844304 -- 0 --&gt; 140297927001872\n140297928844304 -- 1 --&gt; 140297927011664\n140297928835536[4]\n140297928835536 -- 0 --&gt; 140297927009296\n140297928835536 -- 1 --&gt; 140297263880592\n140297928836048[4]\n140297928836048 -- 0 --&gt; 140297927015056\n140297928836048 -- 1 --&gt; 140297927003152\n140297928849168[4]\n140297928849168 -- 0 --&gt; 140297927013200\n140297928849168 -- 1 --&gt; 140297927009936\n140297927011408['E': 4]\n140297927014160['P': 3]\n140297927001872[2]\n140297927001872 -- 0 --&gt; 140297927004112\n140297927001872 -- 1 --&gt; 140297927004240\n140297927011664[2]\n140297927011664 -- 0 --&gt; 140297927010000\n140297927011664 -- 1 --&gt; 140297927005328\n140297927009296[2]\n140297927009296 -- 0 --&gt; 140297927011536\n140297927009296 -- 1 --&gt; 140297927004560\n140297263880592[2]\n140297263880592 -- 0 --&gt; 140297927013904\n140297263880592 -- 1 --&gt; 140297927014288\n140297927015056['O': 2]\n140297927003152['T': 2]\n140297927013200['Y': 2]\n140297927009936['D': 2]\n140297927004112['W': 1]\n140297927004240['R': 1]\n140297927010000['C': 1]\n140297927005328['H': 1]\n140297927011536['S': 1]\n140297927004560['K': 1]\n140297927013904['L': 1]\n140297927014288['N': 1]\n\n\n\n\n\n\n\n\nHuffman code\nFinally, the Huffman coded result is below.\n\n\nAN APPLE A DAY KEEPS THE DOCTOR AWAY\n\n001 01111 000 001 111 111 01110 110 000 001 000 1011 001 1010 000 01101 \n110 110 111 01100 000 1001 01011 110 000 1011 1000 01010 1001 1000 01001 \n000 001 01000 001 1010 \n\n132 bits / 16.5 bytes\ncompression rate: 54.2%\n\n\nYou might be familiar with the pangram THE QUICK BROWN FOX JUMPS OVER THE LAZY DOG. It contains all the letters from A to Z, which makes it harder to compress.\n\n\nTHE QUICK BROWN FOX JUMPS OVER THE LAZY DOG\n\n00011 00010 0101 001 11111 00001 11110 11101 11100 001 11011 00000 0100 \n11010 11001 001 11000 0100 10111 001 10110 00001 10101 10100 10011 001 0100 \n10010 0101 00000 001 00011 00010 0101 001 10001 10000 01111 01110 001 01101 \n0100 01100 \n\n192 bits / 24.0 bytes\ncompression rate: 44.2%\n\n\nJust for fun, let’s apply Huffman coding to images.\n\n\n\n\n\n\n\n\n\n\n\n(a) Mondriaan\n\n\n\n\n\n\n\n\n\n\n\n(b) Monet\n\n\n\n\n\n\n\nFigure 1: Image compression\n\n\n\nBoth Figure 1 (a) and Figure 1 (b) are resized to 100x100 greyscale images. Each pixel is represented by the intensity of light from 0 to 255 which corresponds to one byte of information. This results in 10000 bytes for each image.\nAfter applying Huffman coding to each image, each is compressed to 7903.6 bytes and 8354.9 bytes, respectively.\nSo, why do we think Figure 1 (a) is easier to draw? Why is it easier to remember pop music notes than those of bebop jazz?\nIt becomes clear when explained using data compression. Since it has a higher compression rate, it can be described verbally or communicated with a shorter and more compact explanation."
  },
  {
    "objectID": "posts/HuffmanCoding.html#average-codeword-length-per-character-barlambda",
    "href": "posts/HuffmanCoding.html#average-codeword-length-per-character-barlambda",
    "title": "Huffman Coding",
    "section": "Average codeword length per character (\\(\\bar{\\lambda}\\))",
    "text": "Average codeword length per character (\\(\\bar{\\lambda}\\))\nLet’s use some notations from now on.\n\\[\n\\bar \\lambda = \\mathbb E [\\lambda] = \\sum_{i=1}^N p(x_i) \\lambda_i\n\\]\n\n\\(\\lambda_i\\): codeword length for the character \\(x_i\\)\n\\(p(x_i)\\): probability of the character \\(x_i\\) occurring\n\nFor the phrase AN APPLE A DAY KEEPS THE DOCTOR AWAY, \\(\\bar \\lambda\\) is 3.667 with the unit in bits."
  },
  {
    "objectID": "posts/HuffmanCoding.html#sec-kraft-mcmillan-inequality",
    "href": "posts/HuffmanCoding.html#sec-kraft-mcmillan-inequality",
    "title": "Huffman Coding",
    "section": "Kraft-McMillan inequality",
    "text": "Kraft-McMillan inequality\nIn coding theory, the Kraft–McMillan inequality gives a necessary and sufficient condition for the existence of a prefix code1.\nWhen we discuss about the upper bound of \\(\\lambda_i\\), we are assuming the worst case scenario for each \\(x_i\\).\nAssert \\(p_i\\) is smallest among all probabilities. Let’s sort all \\(p\\) in the descending order, just before picking the least occuring two.\n                 1   &lt;- until the end\n                  \\\n                   .\n                    .\n                     \\\n         ... &gt;= p &gt;= p_i''   &lt;- and again\n                        \\\n       ... &gt;= p &gt;= p &gt;= p_i'   &lt;- and again\n                       /   \\\n... &gt;= p &gt;= p &gt;= p &gt;= p &gt;= p_i   &lt;- we are at the very end\n           / \\  / \\\n          .        p\n         .        / \\\nThe parent of each node accumulates the minimum possible value, which follows powers of \\(2\\). This accumulation process stops when we reach the root. We can set each \\(\\lambda_i\\) as the stopping condition, defined by reaching the root.\n\\[\n2^{\\lambda_i} p_i \\geq 1\n\\]\nWe cannot stop the iteration until the cumulative probability reaches \\(1\\). The upper inequality represents a partial form of the Kraft-McMillan inequality.\n\\[\\begin{align*}\n2^{\\lambda_i} p_i &\\geq 1 \\\\\np_i &\\geq 2^{-\\lambda_i} \\\\\n\\sum_{i=1}^{N} p_i &\\geq \\sum_{i=1}^{N} 2^{-\\lambda_i} \\\\\n\\sum_{i=1}^{N} 2^{-\\lambda_i} &\\leq 1 \\quad \\cdots \\text{Kraft-McMillan Inequality} \\\\\n\\end{align*}\\]\nWe can add a condition when reaching the root. Since we are assuming \\(\\lambda_i\\) to be the necessary and sufficient number of steps, we can say that if, after iterating \\(\\lambda_i - 1\\) times, we have not reached the root, the process should continue.\n\\[\n2^{\\lambda_i - 1} p_i &lt; 1\n\\]\nWe can represent this in a figure like below.\n\n\n\n\n\n\nFigure 2: Kraft-McMillan inequality\n\n\n\nIn Figure 2, all \\(\\lambda_i\\) are integers. We are assigning the total width of \\(1\\) by the power of 2 for each codewords.\nBy combining two inequalities of stopping conditions:\n\\[\n\\log_2 \\dfrac{1}{p_i} \\leq \\lambda_i &lt; \\log_2 \\dfrac{1}{p_i} + 1\n\\]\n\\(\\lambda_i\\) is considered as an positive integer. Thus,\n\\[\n\\lambda_i = \\left\\lceil \\log_2 \\dfrac{1}{p_i} \\right\\rceil\n\\]"
  },
  {
    "objectID": "posts/HuffmanCoding.html#footnotes",
    "href": "posts/HuffmanCoding.html#footnotes",
    "title": "Huffman Coding",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nKraft-McMillan inequality - Wikipedia↩︎"
  },
  {
    "objectID": "posts/JensensInequality.html",
    "href": "posts/JensensInequality.html",
    "title": "Jensen’s Inequality",
    "section": "",
    "text": "Checkout this post to see the background behind this.\nJensen’s inequality generalizes the statement that the secant line of a convex function lies above the graph of the function1.\n\\(f:\\mathbb R \\to \\mathbb R\\) is convex when,\n\\[\n\\forall t \\in [0,1], f(tx_1 + (1-t)x_2) \\leq tf(x_1)+(1-t)f(x_2)\n\\]"
  },
  {
    "objectID": "posts/JensensInequality.html#jensens-inequality-with-probability-theory",
    "href": "posts/JensensInequality.html#jensens-inequality-with-probability-theory",
    "title": "Jensen’s Inequality",
    "section": "Jensen’s inequality with probability theory",
    "text": "Jensen’s inequality with probability theory\n\n\n\n\n\n\nFigure 2: Jensen’s inequality with probability theory\n\n\n\nWhen \\(\\varphi: \\mathbb R \\to \\mathbb R\\) is a convex function,\n\\[\n\\begin{align*}\n\\varphi(\\mathbb E [X]) &\\leq \\mathbb E [\\varphi(X)] \\\\[10pt]\n\\varphi \\left( \\sum p(x_i) \\ x_i \\right) &\\leq \\sum p(x_i) \\varphi(x_i) \\\\\n\\end{align*}\n\\]\n\nFinite form\nWhen \\(\\varphi: \\mathbb R \\to \\mathbb R\\) is a convex function,\n\\[\n\\varphi \\left( \\dfrac{\\sum a_i x_i}{\\sum a_i} \\right) \\leq \\dfrac{\\sum a_i \\varphi(x_i)}{\\sum a_i}\n\\]\nJensen’s inequality also can be applied under weighted average conditions. Weighted average of \\(\\varphi(x_i)\\) can reside in the dashed quardrangle (including the dashed line).\n\n\nExamples\n\\[\n\\mathrm{Var}[X] = \\mathbb E[X^2] - \\mathbb E[X]^2\n\\]\nWhen \\(\\varphi: x \\mapsto x^2\\), \\(\\varphi\\) is convex, which makes \\(\\mathbb E[X]^2 \\leq \\mathbb E[X^2]\\). This is correct because the variance of random variables cannot be negative."
  },
  {
    "objectID": "posts/JensensInequality.html#footnotes",
    "href": "posts/JensensInequality.html#footnotes",
    "title": "Jensen’s Inequality",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nJensen’s inequality - Wikipedia↩︎"
  },
  {
    "objectID": "posts/MeasureingDistributions.html",
    "href": "posts/MeasureingDistributions.html",
    "title": "Measuring Distributions",
    "section": "",
    "text": "Entropy plays an important role in measuring probability distributions (or RVs). Besides coding theories such as Huffman and Shannon-Fano, etc., it helps quantify the amount of information using only probability.\n\\[\nH(X) =\nH(p) =\nH(p,p) =\n\\sum_{\\mathbf x \\in \\mathcal X} p_X(\\mathbf x) \\log \\dfrac{1}{p_X(\\mathbf x)}\n\\]\nThus, we can define entropy as a scalar function of an arbitrary probability mass function (PMF). We often write \\(H(X)\\) as \\(H(p)\\), same for the differential entropy: \\(h(X)\\) as \\(h(f)\\)1.\nOne thing to become accustomed to is using \\(\\mathbb E\\) and \\(\\sum_x p(x)\\) (or \\(\\int_\\mathcal{X} f(x)\\), depending on the RVs) interchangeably.\nIn the previous posts of Huffman coding and entropy, we have derived that entropy is the the lower bound of average codeword length (\\(\\bar \\lambda\\)), simultaniously meaning the optimality of codeword length.\nFor the dedicated data distribution, the best encoding strategy to achieve the shortest codeword length is using the codewords with repective to the frequency of its own data distribution. Shorter codewords length for more frequent random variable.\nThe optimality in Huffman coding is expressed as follows. Huffman coding achieves optimality in lossless coding using a greedy algorithm.\n\\[\n\\sum_{i=1}^N p_i \\lambda_i \\leq\n\\sum_{i=1}^N p_i \\lambda_i^{'}\n\\]\nSimilarly, the optimality for entropy can be expressed with Gibbs’ inequality.\n\\[\n\\sum_{i=1}^{N} p_i \\log \\dfrac{1}{p_i} \\leq \\sum_{i=1}^{N} p_i \\log \\dfrac{1}{q_i}\n\\]\nWhat this tells you is that for the given distribution \\(P\\), \\(-\\log P\\) is global optimal."
  },
  {
    "objectID": "posts/MeasureingDistributions.html#proving-gibbs-inequality",
    "href": "posts/MeasureingDistributions.html#proving-gibbs-inequality",
    "title": "Measuring Distributions",
    "section": "Proving Gibbs’ inequality",
    "text": "Proving Gibbs’ inequality\n\\[\\begin{align*}\n&\\sum_{i=1}^{N} p_i \\log \\dfrac{1}{q_i} - \\sum_{i=1}^{N} p_i \\log \\dfrac{1}{p_i} \\\\\n=& \\sum_{i=1}^{N} p_i \\log \\dfrac{p_i}{q_i} \\\\\n=& \\sum_{i=1}^{N} p_i \\left( -\\log \\dfrac{q_i}{p_i} \\right) \\\\\n\\geq& -\\log \\sum_{i=1}^{N} p_i \\dfrac{q_i}{p_i} \\quad \\cdots \\text{Jensen's inequality} \\\\\n=& -\\log \\sum_{i=1}^{N} q_i \\\\\n=& \\, 0\n\\end{align*}\\]"
  },
  {
    "objectID": "posts/MeasureingDistributions.html#kullback-leibler-divergence",
    "href": "posts/MeasureingDistributions.html#kullback-leibler-divergence",
    "title": "Measuring Distributions",
    "section": "Kullback-Leibler divergence",
    "text": "Kullback-Leibler divergence\nWe can reform the upper inequality as below. \\(H(p,q)\\) is called the cross entropy.\n\\[\nD_\\text{KL}(p \\| q) \\triangleq H(p,q) - H(p,p)\n\\]\n\\[\nH(p,q) - H(p,p) = \\sum_{i=1}^{N} p_i \\log \\dfrac{p_i}{q_i} \\geq 0\n\\]\n\\[\nD_\\text{KL}(p \\| q) = 0 \\iff p = q\n\\]\nEntropy of distribution is less than or equal to its cross entropy with any other distribution. The difference between the two quantities is the Kullback-Leibler divergence (relative entropy).\nMurphy (2013) states that the cross entropy is the average number of bits needed to encode data coming from a source with distribution \\(p\\) when we use model \\(q\\) to define our codebook. The Kullback Leibler (KL) divergence is the average number of extra bits needed to encode the data, due to the fact that we used distribution \\(q\\) to encode the data instead of the true distribution \\(p\\).\n\nJensen-Shannon divergence\nAs you can see from the definition, it is generally not the case that \\(D_\\text{KL}(p \\| q) = D_\\text{KL}(q \\| p)\\). In some cases, it is useful to define a non-negative scalar between the two distributions that can act as a symmetric distance metric.\n\\[\n\\mathrm{JSD}(p \\| q) =\n\\dfrac{1}{2} D_\\text{KL}\\left(p \\, \\bigg\\| \\, \\dfrac{p+q}{2} \\right) +\n\\dfrac{1}{2} D_\\text{KL}\\left(q \\, \\bigg\\| \\, \\dfrac{p+q}{2} \\right)\n\\]\nThis will satisfy \\(\\mathrm{JSD}(p \\| q) = \\mathrm{JSD}(q \\| p)\\).\nSince \\(D_\\text{KL}\\) is non-negative, \\(\\mathrm{JSD}\\) also inherits this property. This will become useful when deriving the optimality of GANs."
  },
  {
    "objectID": "posts/MeasureingDistributions.html#mutual-information",
    "href": "posts/MeasureingDistributions.html#mutual-information",
    "title": "Measuring Distributions",
    "section": "Mutual information",
    "text": "Mutual information\nConsider two random variables, \\(X\\) and \\(Y\\). Suppose we want to know how much knowing one variable tells us about the other. The more they are correlated, the more different \\(p(X,Y)\\) and \\(p(X)p(Y)\\) will get. Defining the \\(D_\\text{KL}\\) between \\(p(X,Y)\\) and \\(p(X)p(Y)\\) can represent how different \\(p(X,Y)\\) is from independence.\n\\[\nI(X;Y) \\triangleq D_\\text{KL}(p(X,Y) \\| p(X)p(Y))\n= \\sum_{x} \\sum_{y} p(x,y) \\log \\dfrac{p(x,y)}{p(x)p(y)}\n\\]\n\\[\nI(X;Y) = 0 \\iff p(X,Y) = p(X)p(Y) \\iff X \\perp Y\n\\]\n\n\n\n\n\n\n\n\n\n\n\n(a) p(X,Y)\n\n\n\n\n\n\n\n\n\n\n\n(b) p(X)p(Y)\n\n\n\n\n\n\n\nFigure 1: Mutual Information"
  },
  {
    "objectID": "posts/MeasureingDistributions.html#footnotes",
    "href": "posts/MeasureingDistributions.html#footnotes",
    "title": "Measuring Distributions",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nECE 587 / STA 563: Lecture 7 - Diﬀerential Entropy↩︎"
  },
  {
    "objectID": "posts/RaspiK8s.html",
    "href": "posts/RaspiK8s.html",
    "title": "Kubernetes Cluster with Raspberry Pi",
    "section": "",
    "text": "Start building your own Kubernetes (K8s) cluster with Raspberry Pi!\nCheck out this video from NetworkChuck for guidance and inspiration.\nI’ve chosen to create a fully-fledged K8s cluster on Raspberry Pi, as a hands-on way to learn and troubleshoot Kubernetes. If you’d prefer a simpler setup, consider using lightweight distributions like K3s or K0s, which are optimized for ease of use on resource-constrained devices."
  },
  {
    "objectID": "posts/RaspiK8s.html#materials",
    "href": "posts/RaspiK8s.html#materials",
    "title": "Kubernetes Cluster with Raspberry Pi",
    "section": "Materials",
    "text": "Materials\nHere are the materials I started with to set up my Raspberry Pi Kubernetes cluster:\n\n4 \\(\\times\\) Raspberry Pi 4 Model B (4GB)\n4 \\(\\times\\) Micro SD cards (128GB)\n4 \\(\\times\\) RJ45 Ethernet cables\n4 \\(\\times\\) USB Type-C cables\n4 \\(\\times\\) USB chargers\n1 \\(\\times\\) Network switch\n1 \\(\\times\\) Acrylic tower case\n\nOnce assembled, the end product will look like this:\n\n\n\nRaspberry Pi Kubernetes Cluster\n\n\nThat wraps up the hardware setup! Now it’s time for the fun part."
  },
  {
    "objectID": "posts/RaspiK8s.html#installing",
    "href": "posts/RaspiK8s.html#installing",
    "title": "Kubernetes Cluster with Raspberry Pi",
    "section": "Installing",
    "text": "Installing\n\nOperating system\nLet’s start by installing the OS. For this project, we’ll be using ubuntu-20.04.5-preinstalled-server-arm64+raspi.img.\nLet’s bake some images onto the microSD cards. This part can feel tedious, but fortunately, there is a dedicated Raspberry Pi Imager from the official project that simplifies the process. It lets you select an OS from a dropdown list and burn images to the SD cards.\ncloud-init gets handy when installing with configurations. it streamlines the process of setting up and configuring instances, whether you’re dealing with a cloud VM or a local server. By tweaking settings in user-data and network-config, you can:\n\nSet up user accounts, SSH keys.\nInstall packages or run scripts on the first boot.\nConfigure network settings like static IP addresses or DNS.\n\nFor my case, the network architecture is configured as:\nISP ─── modem\n          │\n        router ─── L2 switch\n     192.168.0.1       │\n          │            ├── knode-01  192.168.0.10\n        macbook        ├── knode-02  192.168.0.11\n    192.168.0.100      ├── knode-03  192.168.0.12\n                       └── knode-04  192.168.0.13\nThe knode-01 will be configured as a control plane and rest as worker nodes. Check the example network-config file below.\n\n\nnetwork-config\n\nversion: 2\nethernets:\n  eth0:\n1    dhcp4: no\n    addresses:\n      - 192.168.0.10/24\n    gateway4: 192.168.0.1\n    nameservers:\n      addresses:\n        - 8.8.8.8\n        - 8.8.4.4\n\n\n1\n\nChange the IPv4 address of the physical Raspberry Pi node by disabling DHCP and setting a static IP.\n\n\nThe Raspberry Pi will boot up within a couple of minutes. The ol’ping works great for checking the state (otherwise you can try using AngryIPScanner).\nAfter booting up the servers, I recommend using tmux simply helps you run the same command across multiple SSH sessions simultaneously. Turn the sync on/off with Ctrl-bCtrl-b :: setw synchronize-panes on/off.\n\n\nKubernetes\nThe official documentation is here.\nAlso there are plenty of tutorials out there. A blog post by Daniel and a youtube by NetworkChuck helped me a lot.\nMainly, there are three components to install. Those are:\n\nkubelet: Runs on each node in a Kubernetes cluster, managing containerized applications and ensuring their health.\nkubeadm: Assists in setting up and configuring Kubernetes clusters by initializing the control plane and joining nodes.\nkubectl: Command-line tool for interacting with the Kubernetes API, enabling deployment, management, and troubleshooting of applications within the cluster.\n\nFollow the steps below.\n\nTurn off swap memory perpetually\n1sudo swapoff -a\n2sudo sed -i '/ swap / s/^/#/' /etc/fstab\nfree -h\n\n1\n\nTurns off swap memory temporarily.\n\n2\n\nDisables swap on boot to keep it turned off after rebooting.\n\n\n\n\nInstall CRI runtime\nkubelet requires a CRI runtime to work. In this tutorial, we will be installing containerd.\nThis tutorial follows the official installation guide.\nsudo apt-get update\nsudo apt-get install -y apt-transport-https ca-certificates curl gpg\ncurl -fsSL https://pkgs.k8s.io/core:/stable:/v1.31/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg\n\nfor pkg in docker.io docker-doc docker-compose docker-compose-v2 podman-docker containerd runc; do sudo apt-get remove $pkg; done\n\nsudo apt-get update\nsudo apt-get install ca-certificates curl\nsudo install -m 0755 -d /etc/apt/keyrings\nsudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc\nsudo chmod a+r /etc/apt/keyrings/docker.asc\n\necho \\\n  \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \\\n  $(. /etc/os-release && echo \"$VERSION_CODENAME\") stable\" | \\\n  sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\n\nsudo apt-get update\nsudo apt install -y containerd.io\n\n\nConfigure CRI runtime\nCheck the official guide\nsudo sed -i '$ s/$/ cgroup_enable=cpuset cgroup_enable=memory cgroup_memory=1 swapaccount=1/' /boot/firmware/cmdline.txt\n\ncat &lt;&lt;EOF | sudo tee /etc/sysctl.d/k8s.conf\nnet.bridge.bridge-nf-call-ip6tables = 1 \nnet.bridge.bridge-nf-call-iptables = 1 \nnet.ipv4.ip_forward = 1\nEOF\nsudo sysctl --system\n\ncat &lt;&lt;EOF | sudo tee /etc/modules-load.d/containerd.conf\noverlay\nbr_netfilter\nEOF\n\nsudo mkdir -p /etc/containerd\ncontainerd config default | sudo tee /etc/containerd/config.toml\n\n\n/etc/containerd/config.toml\n\n[plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.runc]\n  ...\n  [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.runc.options]\n1    SystemdCgroup = true\n\n\n1\n\nThe SystemdCgroup parameter is a configuration setting in container runtimes, such as containerd, to manage cgroups (control groups) using systemd rather than relying on the runtime’s native cgroup management. Setting SystemdCgroup=true enables systemd to control the cgroup hierarchy for containers.\n\n\nsudo systemctl restart containerd\n\n\nkubelet, kubeadm and kubectl\nsudo systemctl restart containerd\n\nsudo apt-get update\nsudo apt-get install -y apt-transport-https ca-certificates curl gpg\ncurl -fsSL https://pkgs.k8s.io/core:/stable:/v1.31/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg\necho 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.31/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list\n\nsudo apt-get update\nsudo apt-get install -y kubelet kubeadm kubectl\nsudo apt-mark hold kubelet kubeadm kubectl\n\nsudo systemctl enable --now kubelet\n\n\nInitialize control-plane\nWe are planning to use Flannel for container networking.\nFirstly, initialize the control plane with kubeadm init command and later join the worker nodes.\nsudo kubeadm init --pod-network-cidr=10.244.0.0/16\n\nmkdir -p $HOME/.kube\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\n\n\nJoin worker nodes\n1kubeadm join 192.168.0.10:6443 \\\n  --token 1b120a.0349bfe2a349b331 \\ \n  --discovery-token-ca-cert-hash \\\n    sha256:09321a32...39058c12\n\n1\n\nThe IP address for the control plane’s API server with the port defaulting to 6443.\n\n\n\n\nApply CNI plugin\nFlannel is a popular CNI (Conatainer Networking Interface) plugin in Kubernetes that provides an unified network across the entire cluster.\nFlannel enables this by:\n\nOverlay Network: Flannel creates an overlay network, allowing pods on different nodes to communicate as though they were on the same local network. This abstraction flattens the network by providing a single, consistent IP address space for all pods within the cluster.\nIP Address Management: Each pod receives a unique IP address within this flat network, enabling packets to travel between nodes without requiring complex routing or Network Address Translation (NAT). This makes inter-node communication more straightforward.\nFlexible Backends: Flannel offers different backends to implement the overlay network. For example:\n\nVXLAN: This backend encapsulates network traffic in UDP packets, enabling scalable and simple flat networking.\nHost-GW: This backend enables direct routing between nodes on the same subnet, which can be useful in specific networking environments.\n\n\nSSH into the control-plane and create pods for CNI networking.\nwget https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml\nkubectl apply -f kube-flannel.yml\n\n\nApply LoadBalancer\nWe have created a baremetal Kubernetes cluster. To properly load balance services, consider using MetalLB.\nwget https://raw.githubusercontent.com/metallb/metallb/v0.14.8/config/manifests/metallb-native.yaml\nkubectl apply -f metallb-native.yaml\n\n\nmetallb-config.yaml\n\napiVersion: metallb.io/v1beta1\nkind: IPAddressPool\nmetadata:\n  name: metallb-pool-01\n  namespace: metallb-system\nspec:\n  addresses:\n1  - 192.168.0.20-192.168.0.30\n---\napiVersion: metallb.io/v1beta1\nkind: L2Advertisement\nmetadata:\n  name: metallb-adv-01\n  namespace: metallb-system\nspec:\n  ipAddressPools:\n  - metallb-pool-01\n\n\n1\n\nThis IP range is used by MetalLB to assign external IPs to LoadBalancer services. Ensure that the range falls within your network’s subnet (e.g., 192.168.0.0/24)\n\n\nkubectl apply -f metallb-config.yaml\n\n\nEnabling NVIDIA driver in Kubernetes\nI found a well documented tutorial post by Deagwon Bu. Highly regared.\n\n\n\n\n\n\nNote\n\n\n\nThe version of the NVIDIA driver on the host sets the upper limit for the NVIDIA runtime version that can be utilized in the container.\n\n\nFirstly, install the nvidia-container-toolkit to enable GPU-accelerated containers. There is an official install guide for this.\ncurl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\\n  && curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \\\n    sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \\\n    sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list\n\nsudo apt-get update\nsudo apt-get install -y nvidia-container-toolkit\nWhen using containerd, config.toml is where NVIDIA drivers are defined.\n\n\n/etc/containerd/containerd.toml\n\n[plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes]\n  ...\n  [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.runc]\n    ...\n    [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.runc.options]\n      ...\n      SystemdCgroup = true\n\n  [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.nvidia]\n    privileged_without_host_devices = false\n    runtime_engine = \"\"\n    runtime_root = \"\"\n    runtime_type = \"io.containerd.runc.v1\"\n\n    [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.nvidia.options]\n      BinaryName = \"/usr/bin/nvidia-container-runtime\"\n      SystemdCgroup = true\n\nsudo systemctl restart containerd\nWhen using K3s by Rancher, also amend the following file:\n\n\n/var/lib/rancher/k3s/agent/etc/containerd/config.toml\n\n[plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.\"nvidia\"]\n  runtime_type = \"io.containerd.runc.v2\"\n\n[plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.\"nvidia\".options]\n  BinaryName = \"/usr/bin/nvidia-container-runtime\"\n  SystemdCgroup = true\n\nsudo systemctl restart k3s\nnodeSelector can be useful when applying NVIDIA plugin to only GPU enabled nodes.\nkubectl label nodes &lt;node&gt; gpu=nvidia\n\nwget https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/v0.16.2/deployments/static/nvidia-device-plugin.yml\n\n\nnvidia-device-plugin.yml\n\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: nvidia-device-plugin-daemonset\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      name: nvidia-device-plugin-ds\n  updateStrategy:\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        name: nvidia-device-plugin-ds\n    spec:\n1      nodeSelector:\n        gpu: nvidia\n        ...\n\n\n1\n\nAdd the following lines.\n\n\nkubectl apply -f nvidia-device-plugin.yml\nCreate the file below and apply it.\n\n\nnvidia-runtime-class.yml\n\napiVersion: node.k8s.io/v1\nkind: RuntimeClass\nmetadata:\n  name: nvidia\nhandler: nvidia\n\nkubectl apply -f nvidia-runtime-class.yml\nIt’s all set! Run pods with GPU resource. Check the template below.\n\n\ngpu-test.yaml\n\napiVersion: v1\nkind: Pod\nmetadata:\n  name: gpu-pod\nspec:\n  restartPolicy: Never\n1  runtimeClassName: nvidia\n2  nodeSelector:\n    gpu: nvidia\n  containers:\n  - name: gpu-container\n    image: nvidia/cuda:12.1.0-runtime-ubuntu20.04\n    resources:\n      limits:\n        cpu: \"500m\"\n        memory: \"1Gi\"\n3        nvidia.com/gpu: 2\n    env:\n    - name: CUDA_VISIBLE_DEVICES\n      value: \"0,1\"\n    - name: TF_FORCE_GPU_ALLOW_GROWTH\n      value: \"true\"\n    - name: CUDA_DEVICE_ORDER\n      value: \"PCI_BUS_ID\"\n\n\n1\n\nSet the runtime defined in config.toml.\n\n2\n\nAllow pod creation in GPU enabled nodes.\n\n3\n\nSet the number of GPUs."
  },
  {
    "objectID": "posts/RaspiK8s.html#accessing",
    "href": "posts/RaspiK8s.html#accessing",
    "title": "Kubernetes Cluster with Raspberry Pi",
    "section": "Accessing",
    "text": "Accessing\nThere are typical authentication methods to access the cluster: Bearer tokens and CA certificates. However, kubectl can support other methods such as client certificates and external authentication providers.\nThe ~/.kube/config file contains the CA certificate issued when initializing the node.\nTo use the same configuration on another system, you can transfer the config file via sftp to the remote computer.\n\n\n~/.kube/context\n\napiVersion: v1\nkind: Config\n\nclusters:\n- name: raspberrypi\n  cluster:\n    certificate-authority-data: &lt;super-secret&gt;\n    server: https://&lt;public-ip&gt;:6443\n\nusers:\n- name: raspberrypi-admin\n  user:\n    client-certificate-data: &lt;super-secret&gt;\n    client-key-data: &lt;super-secret&gt;\n\ncontexts:\n- name: raspberrypi-admin@raspberrypi\n  context:\n    cluster: raspberrypi\n    user: raspberrypi-admin\n\ncurrent-context: raspberrypi-admin@raspberrypi\n\npreferences: {}\n\nWith your router configured to forward requests from the public IP to the private IP, this sould work seamlessly."
  },
  {
    "objectID": "posts/TraefikHelm.html",
    "href": "posts/TraefikHelm.html",
    "title": "Traefik dashboard with Helm",
    "section": "",
    "text": "Check the official Github.\nhelm repo add traefik https://traefik.github.io/charts\nkubectl create ns traefik\nhelm install traefik traefik/traefik \\\n  --set ingressRoute.dashboard.enabled=true \\\n  --namespace traefik"
  },
  {
    "objectID": "posts/TraefikHelm.html#install-traefik-using-helm",
    "href": "posts/TraefikHelm.html#install-traefik-using-helm",
    "title": "Traefik dashboard with Helm",
    "section": "",
    "text": "Check the official Github.\nhelm repo add traefik https://traefik.github.io/charts\nkubectl create ns traefik\nhelm install traefik traefik/traefik \\\n  --set ingressRoute.dashboard.enabled=true \\\n  --namespace traefik"
  },
  {
    "objectID": "posts/TraefikHelm.html#accessing-the-dashboard",
    "href": "posts/TraefikHelm.html#accessing-the-dashboard",
    "title": "Traefik dashboard with Helm",
    "section": "Accessing the dashboard",
    "text": "Accessing the dashboard\n$ k get po -n traefik\nNAME                       READY   STATUS    RESTARTS   AGE\ntraefik-6d574648c7-gwb8t   1/1     Running   0          18m\n\n$ k port-forward -n traefik traefik-6d574648c7-gwb8t 8080:8080\nForwarding from 127.0.0.1:8080 -&gt; 8080\nForwarding from [::1]:8080 -&gt; 8080\nAccess through http://localhost:8080/dashboard/."
  }
]