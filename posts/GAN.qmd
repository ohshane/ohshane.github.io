---
title: GAN
subtitle: ""
description: ""
author: Shane Oh
date: 2024-09-26
image: false
categories:
  - ML
  - Generative Models
bibliography: GAN/references.bib
---

There is an interactive playground available at [GAN Lab](https://poloclub.github.io/ganlab/). 
Feel free to explore it.

## Zero-sum game of a Generator and a Discriminator

A standard (vanilla) GAN consists of two models: a generator and a discriminator.

The generator and discriminator engage in a zero-sum game, where the generator 
tries to produce data that fools the discriminator, while the discriminator aims 
to correctly identify real versus generated (fake) data. This interaction can be 
expressed mathematically with the following objective:

$$
\min_G \max_D V(D,G)
= \mathbb E_{\mathbf x \sim p_\text{data}(\mathbf x)}[\log D(\mathbf x)]
+ \mathbb E_{\mathbf z \sim p_\mathbf{z}(\mathbf z)}[\log (1-D(G(\mathbf z)))]
$$

In this setup, the two players are the generator ($G$) and the discriminator ($D$).
The generator takes a latent variable $\mathbf z$ as input and outputs generated data 
$\mathbf x$. The discriminator takes data $\mathbf x$ as input and outputs a probability 
$y$, representing whether the data is real ($1$) or fake ($0$).

$$
\begin{align*}
G &:\mathbf z \to \mathbf x \\
D &:\mathbf x \to y
\end{align*}
$$

::: {.callout-note}
# Output of a Discriminator
The output of $D$ is a probability that indicates whether $\mathbf{x}$
is genuine.
A value of $1$ corresponds to genuine data, while a value of $0$ indicates fake data.
:::

## The Value Funciton
When breaking down the min-max value function of GANs, it is often easier to 
start with the $D$'s loss. Let's assist no matter what the $G$ attempts 
to produce, it will still be fake.

The value function ($V$) consists of two log-likelihood losses, each from a Bernoulli
distribution: one representing the genuine data distribution and the other, the fake
data distribution.

Let $\mathbf{x} \sim p_\text{data}(\mathbf{x})$ represent a sample drawn from the
genuine data distribution. They are all labeled as $1$.
Same thing for the fake data $\mathbf{z} \sim p_\mathbf{z}(\mathbf{z})$.
They are all labeled as $0$. Those are the ground truths in GANs.

So, how do we assess the performance of $D$?

### The Binary Cross Entropy Loss of $D$
The Binary Cross-Entropy (BCE) is defined as follows.

$$
\mathcal L_\text{BCE}(\hat y, y)
= - \lbrace y \log{\hat y} + (1-y) \log{(1-\hat y)} \rbrace
$$

We can try to optimize the model by decreasing the $\mathcal L$.
Conversely, increasing $-\mathcal L$ resembles the same objective.
When dealing with $D$'s loss, we use the latter approach.

The loss of $D$ is calculated with negative BCE loss on
both real and fake data distributions and are added together.

$$
-\lbrace
    \mathcal L_\text{BCE}(D(\mathbf x), 1)
  + \mathcal L_\text{BCE}(D(G(\mathbf z)), 0)
\rbrace
$$

## Theoretical Bound
![Fig](GAN/images/fig-01.jpg)

@goodfellow2014generativeadversarialnetworks