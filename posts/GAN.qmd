---
title: GAN
subtitle: ""
description: ""
author: Shane Oh
date: 2024-09-26
image: false
categories:
  - ML
  - Generative Models
bibliography: GAN/references.bib
---

There is an interactive playground available at [GAN Lab](https://poloclub.github.io/ganlab/). 
Feel free to explore it.

## Zero-sum game of a Generator and a Discriminator

The zero-sum property (if one gains, another loses) means that any result of a zero-sum situation is Pareto optimal
which is also called a conflict game[^wiki-zero-sum-game].

[^wiki-zero-sum-game]: [Wikipedia - Zero-sum game](https://en.wikipedia.org/wiki/Zero-sum_game)

The generator and discriminator engage in a zero-sum game, where the generator 
tries to produce data that fools the discriminator, while the discriminator aims 
to correctly identify real versus generated (fake) data. This interaction can be 
expressed with a payoff matrix.

:::{=html}
<div id="payoff-matrix">
<table>
  <tr>
    <td></td>
    <td>$D_\text{good}$</td>
    <td>$D_\text{poor}$</td>
  </tr>
  <tr>
    <td>$G_\text{good}$</td>
    <td>$( 0, 0)$</td>
    <td>$( 1,-1)$</td>
  </tr>
  <tr>
    <td>$G_\text{poor}$</td>
    <td>$(-1, 1)$</td>
    <td>$( 0, 0)$</td>
  </tr>
</table>
</div>

<style>
#payoff-matrix table {
  margin: 2em auto;
}

#payoff-matrix tr td {
  border: 1px solid black;
}

#payoff-matrix td {
  width: 6em;
  text-align: center;
}
</style>
:::

The payoff matrix shows all the combinations of what players can move.
The gains for $G$ and $D$ in each state are denoted by tuples.

The best choice for $D$, regardless of what $G$ chooses, is $D_\text{good}$.
When $G$ chooses $G_\text{good}$, $D$ can move from $-1$ to $0$, gaining $+1$, 
and when $G$ chooses $G_\text{poor}$, $D$ can move from $0$ to $1$, also gaining 
$+1$, making $D_\text{good}$ a dominant strategy.
Same for $G$, making $G_\text{good}$ a dominant strategy.

The solution for this game is choosing $D_\text{good}$ and $G_\text{good}$
which is considered as a Nash Equilibrium in GANs,
maximizing both players' gains.

However, the question of whether a Nash Equilibrium exists in the GAN framework
remains open. Read @pmlr-v119-farnia20a to find out more.

Since the GAN framework can be modeled as a zero-sum game,
we can also derive the same Nash Equilibrium
using the second element of the tuples ($D$'s gain), 
which provides a more compact representation.
This becomes the **value function**.

## The Value Funciton

$$
\min_G \max_D V(D,G)
= \mathbb E_{\mathbf x \sim p_\text{data}(\mathbf x)}[\log D(\mathbf x)]
+ \mathbb E_{\mathbf z \sim p_\mathbf{z}(\mathbf z)}[\log (1-D(G(\mathbf z)))]
$$

The generator takes a latent variable $\mathbf z$ as input and outputs generated data 
$\mathbf x$. The discriminator takes data $\mathbf x$ as input and outputs a probability 
$y$, representing whether the data is real ($1$) or fake ($0$).

$$
\begin{align*}
G &:\mathbf z \to \mathbf x \\
D &:\mathbf x \to y
\end{align*}
$$

The value function ($V$) consists of two log-likelihood losses, each from a Bernoulli
distribution: one representing the genuine data distribution and the other, the fake
data distribution.

Let $\mathbf{x} \sim p_\text{data}(\mathbf{x})$ represent a sample drawn from the
genuine data distribution. They are all labeled as $1$.
Same thing for the fake data $\mathbf{z} \sim p_\mathbf{z}(\mathbf{z})$.
They are all labeled as $0$.

### Objective of $D$
The Binary Cross-Entropy (BCE) is defined as follows.

$$
\mathcal L_\text{BCE}(\hat y, y)
= - \lbrace y \log{\hat y} + (1-y) \log{(1-\hat y)} \rbrace
$$

We can try to optimize the model by decreasing the $\mathcal L$.
Conversely, increasing $-\mathcal L$ resembles the same objective.
When dealing with $D$'s loss, we use the latter approach.

The loss of $D$ is calculated with negative BCE loss on
both real and fake data distributions and are added together.

$$
\max_D V(D,G) = 
-\mathcal L_\text{BCE}(D(\mathbf x), 1)
-\mathcal L_\text{BCE}(D(G(\mathbf z)), 0)
$$

$D$ will try to maximize the value function $V(D,G)$
thus, $\theta_\text{d}$ is updated with gradient ascent.

### Objective of $G$

In $G$'s perspective, $G$'s objective is to fool $D$ by
creating more realistic data.

$$
\min_G V(G) = -\mathcal L_\text{BCE}(D(G(\mathbf z)), 0) \\
$$

$G$ will try to minimize the value function $V(G)$
thus, $\theta_\text{d}$ is updated with gradient decent.

::: {.callout-note}
# Unifying the loss with respect to $V$
Note that we are not using $\mathcal L_\text{BCE}(D(G(\mathbf z)), 1)$
as the value function for $G$. In the context of zero-sum loss, we will
try to unify the losses in terms of $V$.
:::

## Theoretical Results
![Training GANs](GAN/images/fig-01.jpg){#fig-training-gans}

The figure above is from @goodfellow2014generativeadversarialnetworks. 
The genuine data distribution $p_\text{data}$ is represented by a
<span style="border-bottom: 2px dotted;">black dotted line</span>. 
and <span style="color: green;">green</span> denotes the generated distribution $p_\text{g}$,
and lastly the color <span style="color: blue;">blue</span> denotes the discriminated distribution, 

As mentioned above, the output of $D$ is the probability that the data is genuine, 
so the height of the <span style="color: blue;">blue</span> bar represents the corresponding value between $[0, 1]$.
The value of the <span style="color: blue;">blue</span> distribution is one-half on $x$, 
where $x$ represents the intersection of the <span style="border-bottom: 2px dotted;">black</span> and <span style="color: blue;">blue</span> lines.

### Global Optimum of $V$

We reach the global optimum of $V$ when we approach optimal $D$ and $G$.

\begin{align*}
V(D,G)
&= \mathbb E_{\mathbf x \sim p_\text{data}(\mathbf x)}[\log D(\mathbf x)]
+ \mathbb E_{\mathbf z \sim p_\mathbf{z}(\mathbf z)}[\log (1-D(G(\mathbf z)))] \\

&= \int_\mathbf{x} p_\text{data}(\mathbf x) \log D(\mathbf x) d \mathbf x
+ \int_\mathbf{z} p_\mathbf{z}(\mathbf z) \log (1 - D(G(\mathbf z)) d \mathbf z \\

&= \int_\mathbf{x} p_\text{data}(\mathbf x) \log D(\mathbf x) d \mathbf x
+ \int_\mathbf{x} p_\text{g}(\mathbf x) \log (1 - D(\mathbf x) d \mathbf x \\

&= \int_\mathbf{x} p_\text{data}(\mathbf x) \log D(\mathbf x)
                + p_\text{g}(\mathbf x) \log (1 - D(\mathbf x) d \mathbf x
\end{align*}

By setting $p_\text{data}(\mathbf x)$ as $a$ and $p_\text{g}(\mathbf x)$ as $b$,
