---
title: GAN
subtitle: "Which Comes First? Generator or Discriminator?"
description: ""
author: Shane Oh
date: 2024-09-26
image: false
categories:
  - ML
  - Generative Models
bibliography: GAN/references.bib
---

There is an interactive playground available at [GAN Lab](https://poloclub.github.io/ganlab/). 
Feel free to explore it.

## Zero-sum game of a Generator and a Discriminator

The zero-sum property (if one gains, another loses) means that any result of a zero-sum situation is Pareto optimal
which is also called a conflict game[^wiki-zero-sum-game].

[^wiki-zero-sum-game]: [Wikipedia - Zero-sum game](https://en.wikipedia.org/wiki/Zero-sum_game)

The generator and discriminator engage in a zero-sum game, where the generator 
tries to produce data that fools the discriminator, while the discriminator aims 
to correctly identify real versus generated (fake) data. This interaction can be 
expressed with a payoff matrix.

:::{=html}
<div id="payoff-matrix">
<table>
  <tr>
    <td></td>
    <td>$D_\text{good}$</td>
    <td>$D_\text{poor}$</td>
  </tr>
  <tr>
    <td>$G_\text{good}$</td>
    <td>$( 0, 0)$</td>
    <td>$( 1,-1)$</td>
  </tr>
  <tr>
    <td>$G_\text{poor}$</td>
    <td>$(-1, 1)$</td>
    <td>$( 0, 0)$</td>
  </tr>
</table>
</div>

<style>
#payoff-matrix table {
  margin: 2em auto;
}

#payoff-matrix tr td {
  border: 1px solid black;
}

#payoff-matrix td {
  width: 6em;
  text-align: center;
}
</style>
:::

The payoff matrix shows all the combinations of what players can move.
The gains for $G$ and $D$ in each state are denoted by tuples.

The best choice for $D$, regardless of what $G$ chooses, is $D_\text{good}$.
When $G$ chooses $G_\text{good}$, $D$ can move from $-1$ to $0$, gaining $+1$, 
and when $G$ chooses $G_\text{poor}$, $D$ can move from $0$ to $1$, also gaining 
$+1$, making $D_\text{good}$ a dominant strategy.
Same for $G$, making $G_\text{good}$ a dominant strategy.

The solution for this game is choosing $D_\text{good}$ and $G_\text{good}$
which is considered as a Nash Equilibrium in GANs,
maximizing both players' gains.

However, the question of whether a Nash Equilibrium exists in the GAN framework
remains open. Read @pmlr-v119-farnia20a to find out more.

Since the GAN framework can be modeled as a zero-sum game,
we can also derive the same Nash Equilibrium
using the second element of the tuples ($D$'s gain), 
which provides a more compact representation.
This becomes the **value function**.

## The Value Function

$$
\min_G \max_D V(D,G)
= \mathbb E_{\mathbf x \sim p_\text{data}(\mathbf x)}[\log D(\mathbf x)]
+ \mathbb E_{\mathbf z \sim p_\mathbf{z}(\mathbf z)}[\log (1-D(G(\mathbf z)))]
$$

The generator takes a latent variable $\mathbf z$ as input and outputs generated data 
$\mathbf x$. The discriminator takes data $\mathbf x$ as input and outputs a probability 
$y$, representing whether the data is real ($1$) or fake ($0$).

$$
\begin{align*}
G &:\mathbf z \to \mathbf x \\
D &:\mathbf x \to y
\end{align*}
$$

The value function ($V$) consists of two log-likelihood losses, each from a Bernoulli
distribution: one representing the genuine data distribution and the other, the fake
data distribution.

Let $\mathbf{x} \sim p_\text{data}(\mathbf{x})$ represent a **sample** drawn from the
genuine data distribution. They are all labeled as $1$.
Same thing for the fake data $\mathbf{z} \sim p_\mathbf{z}(\mathbf{z})$.
They are all labeled as $0$.

::: {.callout-note}
During training, we will keep the number of samples for $\mathbf{x}$ and $\mathbf{z}$ the same.
:::

### Objective of $D$
The Binary Cross-Entropy (BCE) is defined as follows.

$$
\mathcal L_\text{BCE}(\hat y, y)
= - \lbrace y \log{\hat y} + (1-y) \log{(1-\hat y)} \rbrace
$$

We can try to optimize the model by decreasing the $\mathcal L$.
Conversely, increasing $-\mathcal L$ resembles the same objective.
When dealing with $D$'s loss, we use the latter approach.

The loss of $D$ is calculated with negative BCE loss on
both real and fake data distributions and are added together.

$$
\max_D V(D,G) =
\sum_{\mathbf x}
-\mathcal L_\text{BCE}(D(\mathbf x), 1) +
\sum_{\mathbf z}
-\mathcal L_\text{BCE}(D(G(\mathbf z)), 0)
$$

$D$ will try to maximize the value function $V(D,G)$
thus, $\theta_\text{d}$ is updated with gradient ascent.

### Objective of $G$

In $G$'s perspective, $G$'s objective is to fool $D$ by
creating more realistic data.

$$
\min_G V(G) =
\sum_{\mathbf z}
-\mathcal L_\text{BCE}(D(G(\mathbf z)), 0) \\
$$

$G$ will try to minimize the value function $V(G)$
thus, $\theta_\text{d}$ is updated with gradient descent.

::: {.callout-note}
# Unifying the loss with respect to $V$
Note that we are not using $\mathcal L_\text{BCE}(D(G(\mathbf z)), 1)$
as the value function for $G$. In the context of zero-sum loss, we will
try to unify the losses in terms of $V$.
:::

## Theoretical Results
![Training GANs](GAN/images/fig-01.jpg){#fig-training-gans}

The figure above is from @goodfellow2014generativeadversarialnetworks. 
The genuine data distribution $p_\text{data}$ is represented by a
<span style="border-bottom: 2px dotted;">black dotted line</span>. 
and <span style="color: green;">green</span> denotes the generated distribution $p_\text{g}$,
and lastly the color <span style="color: blue;">blue</span> denotes the discriminated distribution, 

As mentioned above, the output of $D$ is the probability that the data is genuine, 
so the height of the <span style="color: blue;">blue</span> bar represents the corresponding value between $[0, 1]$.
The value of the <span style="color: blue;">blue</span> distribution is one-half on $x$, 
where $x$ represents the intersection of the <span style="border-bottom: 2px dotted;">black</span> and <span style="color: blue;">blue</span> lines.

::: {.callout-note}
The results of this section are done in a non-parametric setting,
e.g. we represent a model with infinite capacity by studying convergence in the
space of **probability density functions**; $p_\text{data}$ and $p_\text{g}$.
:::

We reach the global optimum of $V$ when we approach optimal $D$ and $G$.

### Optimal $D$

Optimal $D$ can be obtained by maximizing $V$. For any given $G$, $D$ will try it's best to
discriminate genuine data from the fake.

\begin{align*}
V(D,G)
&= \mathbb E_{\mathbf x \sim p_\text{data}(\mathbf x)}[\log D(\mathbf x)]
+ \mathbb E_{\mathbf z \sim p_\mathbf{z}(\mathbf z)}[\log (1-D(G(\mathbf z)))] \\

&= \int_\mathbf{x} p_\text{data}(\mathbf x) \log D(\mathbf x) d \mathbf x
+ \int_\mathbf{z} p_\mathbf{z}(\mathbf z) \log (1 - D(G(\mathbf z))) d \mathbf z \\

&= \int_\mathbf{x} p_\text{data}(\mathbf x) \log D(\mathbf x) d \mathbf x
+ \int_\mathbf{x} p_\text{g}(\mathbf x) \log (1 - D(\mathbf x)) d \mathbf x \\

&= \int_\mathbf{x} p_\text{data}(\mathbf x) \log D(\mathbf x)
                + p_\text{g}(\mathbf x) \log (1 - D(\mathbf x)) d \mathbf x
\end{align*}

By setting $p_\text{data}(\mathbf x)$ as $a$ and $p_\text{g}(\mathbf x)$ as $b$,
the inner part of the integral can be expressed as the following.

\begin{align*}
f(y) &= a \log y + b \log (1-y) \\
\dfrac{d}{dy} f(y) &= \dfrac{a}{y} - \dfrac{b}{1-y} = 0 \\
\therefore y &= \frac{a}{a+b}
\end{align*}

The optimal $D$ can be defined as follows.

$$
D^*(\mathbf x) = \dfrac{p_\text{data}(\mathbf x)}{p_\text{data}(\mathbf x) + p_\text{g}(\mathbf x)}
$$

### Optimal $G$

With same $V$, optimal $G$ can be obtained by minimizing $V$.
We will find optimal $G$ with respective to
the optimal discriminator $D^*$.

\begin{align*}
V(D^*,G)
&= \mathbb E_{\mathbf x \sim p_\text{data}(\mathbf x)}[\log D^*(\mathbf x)]
+ \mathbb E_{\mathbf z \sim p_\mathbf{z}(\mathbf z)}[\log (1-D^*(G(\mathbf z)))] \\

&= \mathbb E_{\mathbf x \sim p_\text{data}(\mathbf x)} \left[
  \log \dfrac{p_\text{data}(\mathbf x)}{p_\text{data}(\mathbf x) + p_\text{g}(\mathbf x)}
\right]
+ \mathbb E_{\mathbf z \sim p_\mathbf{z}(\mathbf z)} \left[
  \log \dfrac{p_\text{g}(\mathbf x)}{p_\text{data}(\mathbf x) + p_\text{g}(\mathbf x)}
\right] \\

&= \mathbb E_{\mathbf x \sim p_\text{data}(\mathbf x)} \left[
  \log \dfrac{2 \ p_\text{data}(\mathbf x)}{p_\text{data}(\mathbf x) + p_\text{g}(\mathbf x)}
\right]
+ \mathbb E_{\mathbf z \sim p_\mathbf{z}(\mathbf z)} \left[
  \log \dfrac{2 \ p_\text{g}(\mathbf x)}{p_\text{data}(\mathbf x) + p_\text{g}(\mathbf x)}
\right]
- \log 4 \\

&= \mathbb E_{\mathbf x \sim p_\text{data}(\mathbf x)} \left[
  \log \dfrac{p_\text{data}(\mathbf x)}{\dfrac{p_\text{data}(\mathbf x) + p_\text{g}(\mathbf x)}{2}}
\right]
+ \mathbb E_{\mathbf z \sim p_\mathbf{z}(\mathbf z)} \left[
  \log \dfrac{p_\text{g}(\mathbf x)}{\dfrac{p_\text{data}(\mathbf x) + p_\text{g}(\mathbf x)}{2}}
\right]
- \log 4
\\

&= D_\text{KL} \left( p_\text{data}(\mathbf x) \bigg\| \dfrac{p_\text{data}(\mathbf x) + p_\text{g}(\mathbf x)}{2} \right)
 + D_\text{KL} \left( p_\text{g}(\mathbf x) \bigg\| \dfrac{p_\text{data}(\mathbf x) + p_\text{g}(\mathbf x)}{2} \right) - \log 4 \\

&= 2 \ \mathrm{JSD}(p_\text{data}(\mathbf x) \| p_\text{g}(\mathbf x)) - \log 4 \\

&\geq -\log 4 \\[20pt]

\min_{G} V(D^*, G) &= -\log 4 \iff p_\text{data} = p_\text{g} \\

V(D^*,G^*) &= -\log4
\end{align*}

::: {.callout-note}
# Does the order of $\min$, $\max$ matter?
Yes, it does.  
Mathematically, $\min_G \max_D V(D, G)$ is the same as $\min_G (\max_D V(D, G))$.  
We try to solve from the inner parentheses.  
In GAN's perspective, as long as $D$ tries its best to discriminate the two distributions, the best strategy for $G$ is to mimic $p_\text{data}$ as closely as possible.
:::

```{python}
#| echo: false
#| fig-align: center 
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import norm

x = np.linspace(-10, 10, 201)
p_data = norm.pdf(x, loc=-2, scale=1)
p_g    = norm.pdf(x, loc= 2, scale=2)
d = p_data / (p_data+p_g)

plt.figure(figsize=(4,3))
plt.plot(x, p_data, c='k', ls=':', lw=3, label=r"$p_d$")
plt.plot(x, p_g, c='g', label=r"$p_g$")
plt.plot(x, d, c='b', ls=':', label=r"$D^*$")
plt.fill_between(x, d > 0.5, color='blue', alpha=0.1)
plt.legend()
plt.show()
```